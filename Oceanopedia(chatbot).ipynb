{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asteroiddestroyer911/Oceanopedia-chatbot/blob/main/Oceanopedia(chatbot).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dS90Bsj0lnG",
        "outputId": "f1728a00-0a45-40bf-f599-431daa705cd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üåä MARINE BIODIVERSITY AI CHATBOT TRAINING\n",
            "============================================================\n",
            "ü§ñ Using Ollama Llama 3.2 3B Model\n",
            "üìö Training on Unified Marine Research Dataset\n",
            "üìÑ Single PDF: unified_data.pdf\n",
            "============================================================\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ All packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# üåä Marine Biodiversity AI Chatbot Training - Single PDF Version\n",
        "# Complete setup for training with Llama 3.2 3B via Ollama\n",
        "\n",
        "print(\"üåä MARINE BIODIVERSITY AI CHATBOT TRAINING\")\n",
        "print(\"=\" * 60)\n",
        "print(\"ü§ñ Using Ollama Llama 3.2 3B Model\")\n",
        "print(\"üìö Training on Unified Marine Research Dataset\")\n",
        "print(\"üìÑ Single PDF: unified_data.pdf\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Install all required packages\n",
        "!pip install -q langchain langchain-community langchain-ollama\n",
        "!pip install -q pypdf faiss-cpu sentence-transformers\n",
        "!pip install -q streamlit pyngrok gradio\n",
        "!pip install -q requests beautifulsoup4 numpy pandas\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGPcYMDNElQS",
        "outputId": "c8986a4c-8297-43cc-b88c-3015ba04e07b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü¶ô Installing Ollama...\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "‚úÖ Ollama installed!\n",
            "üîÑ Starting Ollama server...\n",
            "üì• Downloading Llama 3.2 3B model (this may take a few minutes)...\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "‚úÖ Llama 3.2 3B model ready!\n",
            "üéâ Ollama server running successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install Ollama in Colab\n",
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "\n",
        "print(\"ü¶ô Installing Ollama...\")\n",
        "\n",
        "# Download and install Ollama\n",
        "!curl -fsSL https://ollama.ai/install.sh | sh\n",
        "\n",
        "print(\"‚úÖ Ollama installed!\")\n",
        "\n",
        "# Start Ollama server in background\n",
        "import threading\n",
        "import os\n",
        "\n",
        "def start_ollama_server():\n",
        "    \"\"\"Start Ollama server in background\"\"\"\n",
        "    subprocess.run([\"ollama\", \"serve\"], capture_output=False)\n",
        "\n",
        "# Start server thread\n",
        "server_thread = threading.Thread(target=start_ollama_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "print(\"üîÑ Starting Ollama server...\")\n",
        "time.sleep(10)\n",
        "\n",
        "# Pull Llama 3.2 3B model\n",
        "print(\"üì• Downloading Llama 3.2 3B model (this may take a few minutes)...\")\n",
        "!ollama pull llama3.2:3b\n",
        "\n",
        "print(\"‚úÖ Llama 3.2 3B model ready!\")\n",
        "\n",
        "# Test Ollama connection\n",
        "try:\n",
        "    response = requests.post('http://localhost:11434/api/generate',\n",
        "                           json={'model': 'llama3.2:3b', 'prompt': 'Hello', 'stream': False})\n",
        "    if response.status_code == 200:\n",
        "        print(\"üéâ Ollama server running successfully!\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Ollama server connection issue\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Ollama setup error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fsgmx-F5E7SE",
        "outputId": "ceb62a57-a08d-4207-86eb-4a8813cc0322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîó Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive mounted successfully!\n",
            "üìÅ Created working directories:\n",
            "   ‚Ä¢ Marine Data: /content/marine_data\n",
            "   ‚Ä¢ Vector Store: /content/vectorstore\n",
            "\n",
            "üìã Looking for PDF: unified_data.pdf\n",
            "üìÅ Search location: /content/drive/MyDrive\n",
            "‚ùå File not found: /content/drive/MyDrive/unified_data.pdf\n",
            "\n",
            "üìù To fix this:\n",
            "   1. Upload 'unified_data.pdf' to your Google Drive root folder\n",
            "   2. Or update DRIVE_FOLDER path if it's in a subfolder\n",
            "   3. Re-run this cell\n",
            "\n",
            "üîç Checking common locations:\n",
            "   ‚úÖ Found at: /content/drive/MyDrive/Marine_Research_Data/unified_data.pdf\n",
            "   ‚úÖ Copied successfully!\n",
            "\n",
            "üéâ unified_data.pdf is ready for training!\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive and setup marine research data\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"üîó Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive mounted successfully!\")\n",
        "\n",
        "# Setup directories\n",
        "DRIVE_FOLDER = '/content/drive/MyDrive'  # Adjust if your PDF is in a specific folder\n",
        "COLAB_DATA_DIR = '/content/marine_data'\n",
        "VECTORSTORE_DIR = '/content/vectorstore'\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(COLAB_DATA_DIR, exist_ok=True)\n",
        "os.makedirs(VECTORSTORE_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ Created working directories:\")\n",
        "print(f\"   ‚Ä¢ Marine Data: {COLAB_DATA_DIR}\")\n",
        "print(f\"   ‚Ä¢ Vector Store: {VECTORSTORE_DIR}\")\n",
        "\n",
        "# Single unified PDF file\n",
        "pdf_file = 'unified_data.pdf'\n",
        "\n",
        "print(f\"\\nüìã Looking for PDF: {pdf_file}\")\n",
        "print(f\"üìÅ Search location: {DRIVE_FOLDER}\")\n",
        "\n",
        "# Copy PDF from Drive to Colab\n",
        "source_path = f\"{DRIVE_FOLDER}/{pdf_file}\"\n",
        "dest_path = f\"{COLAB_DATA_DIR}/{pdf_file}\"\n",
        "\n",
        "if os.path.exists(source_path):\n",
        "    shutil.copy2(source_path, dest_path)\n",
        "    print(f\"‚úÖ Successfully copied: {pdf_file}\")\n",
        "    file_size = os.path.getsize(dest_path) / (1024*1024)  # Size in MB\n",
        "    print(f\"üìä File size: {file_size:.2f} MB\")\n",
        "else:\n",
        "    print(f\"‚ùå File not found: {source_path}\")\n",
        "    print(f\"\\nüìù To fix this:\")\n",
        "    print(f\"   1. Upload 'unified_data.pdf' to your Google Drive root folder\")\n",
        "    print(f\"   2. Or update DRIVE_FOLDER path if it's in a subfolder\")\n",
        "    print(f\"   3. Re-run this cell\")\n",
        "\n",
        "    # Check common locations\n",
        "    common_paths = [\n",
        "        f\"{DRIVE_FOLDER}/Marine_Research_Data/{pdf_file}\",\n",
        "        f\"{DRIVE_FOLDER}/Research/{pdf_file}\",\n",
        "        f\"{DRIVE_FOLDER}/Documents/{pdf_file}\"\n",
        "    ]\n",
        "\n",
        "    print(f\"\\nüîç Checking common locations:\")\n",
        "    for path in common_paths:\n",
        "        if os.path.exists(path):\n",
        "            print(f\"   ‚úÖ Found at: {path}\")\n",
        "            # Copy from found location\n",
        "            shutil.copy2(path, dest_path)\n",
        "            print(f\"   ‚úÖ Copied successfully!\")\n",
        "            break\n",
        "        else:\n",
        "            print(f\"   ‚ùå Not found: {path}\")\n",
        "\n",
        "# Final check\n",
        "if os.path.exists(dest_path):\n",
        "    print(f\"\\nüéâ unified_data.pdf is ready for training!\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è Please upload unified_data.pdf to Google Drive and re-run this cell\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7CltFqAFFp3",
        "outputId": "77ef12d3-302c-481d-f22e-19e7934d8c10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üåä Unified Marine Biodiversity Chatbot class defined!\n",
            "üöÄ Ready for single PDF training and deployment!\n"
          ]
        }
      ],
      "source": [
        "# Marine Biodiversity Chatbot with Ollama Llama 3.2 3B - Single PDF Version\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_ollama import OllamaLLM\n",
        "from langchain.prompts import PromptTemplate\n",
        "import pickle\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "class MarineBiodiversityChatbot:\n",
        "    def __init__(self, pdf_directory=COLAB_DATA_DIR, vectorstore_path=VECTORSTORE_DIR):\n",
        "        self.pdf_directory = pdf_directory\n",
        "        self.vectorstore_path = vectorstore_path\n",
        "        self.pdf_file = \"unified_data.pdf\"\n",
        "        self.documents = []\n",
        "        self.vectorstore = None\n",
        "        self.qa_chain = None\n",
        "        self.llm = None\n",
        "\n",
        "        # Enhanced marine domain knowledge\n",
        "        self.marine_expertise = {\n",
        "            \"aquaculture\": [\n",
        "                \"fish farming\", \"cultivation\", \"feeding\", \"growth optimization\",\n",
        "                \"health monitoring\", \"precision aquaculture\", \"water quality\",\n",
        "                \"disease detection\", \"automated feeding systems\", \"breeding programs\"\n",
        "            ],\n",
        "            \"conservation\": [\n",
        "                \"biodiversity\", \"ecosystem protection\", \"species conservation\",\n",
        "                \"habitat restoration\", \"marine protected areas\", \"endangered species\",\n",
        "                \"coral reef conservation\", \"marine sanctuaries\", \"wildlife protection\"\n",
        "            ],\n",
        "            \"ai_applications\": [\n",
        "                \"computer vision\", \"machine learning\", \"deep learning\", \"predictive analytics\",\n",
        "                \"automation\", \"sensor networks\", \"image recognition\", \"pattern recognition\",\n",
        "                \"neural networks\", \"data mining\", \"artificial intelligence\"\n",
        "            ],\n",
        "            \"ocean_monitoring\": [\n",
        "                \"water quality monitoring\", \"environmental sensors\", \"data integration\",\n",
        "                \"remote sensing\", \"GIS\", \"satellite monitoring\", \"oceanographic data\",\n",
        "                \"real-time monitoring\", \"environmental parameters\", \"ocean sensors\"\n",
        "            ],\n",
        "            \"sustainability\": [\n",
        "                \"sustainable fishing\", \"ecosystem management\", \"climate change adaptation\",\n",
        "                \"pollution control\", \"sustainable practices\", \"resource management\",\n",
        "                \"environmental impact\", \"green technologies\", \"carbon footprint\"\n",
        "            ],\n",
        "            \"data_science\": [\n",
        "                \"big data\", \"data analytics\", \"statistical analysis\", \"data visualization\",\n",
        "                \"data integration\", \"database management\", \"cloud computing\", \"IoT\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        print(\"üåä Marine Biodiversity Chatbot initialized!\")\n",
        "        print(f\"üìÅ PDF Directory: {self.pdf_directory}\")\n",
        "        print(f\"üìÑ Target PDF: {self.pdf_file}\")\n",
        "        print(f\"üíæ Vector Store: {self.vectorstore_path}\")\n",
        "\n",
        "    def setup_llm(self):\n",
        "        \"\"\"Initialize Ollama Llama 3.2 3B model\"\"\"\n",
        "        print(\"ü¶ô Setting up Llama 3.2 3B model...\")\n",
        "\n",
        "        try:\n",
        "            # Initialize Ollama LLM with optimized parameters\n",
        "            self.llm = OllamaLLM(\n",
        "                model=\"llama3.2:3b\",\n",
        "                base_url=\"http://localhost:11434\",\n",
        "                temperature=0.2,  # Lower for more consistent responses\n",
        "                top_p=0.9,\n",
        "                repeat_penalty=1.1,\n",
        "                num_ctx=4096,  # Context window\n",
        "                num_predict=512  # Max tokens to generate\n",
        "            )\n",
        "\n",
        "            # Test the model with marine context\n",
        "            test_prompt = \"Explain AI applications in marine science briefly.\"\n",
        "            test_response = self.llm.invoke(test_prompt)\n",
        "            print(\"‚úÖ Llama 3.2 3B model ready!\")\n",
        "            print(f\"üß™ Test response preview: {test_response[:150]}...\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error setting up Llama model: {e}\")\n",
        "            return False\n",
        "\n",
        "    def load_unified_document(self):\n",
        "        \"\"\"Load and process the unified marine research PDF\"\"\"\n",
        "        print(f\"\\nüìö Loading unified marine research document: {self.pdf_file}\")\n",
        "\n",
        "        pdf_path = os.path.join(self.pdf_directory, self.pdf_file)\n",
        "\n",
        "        if not os.path.exists(pdf_path):\n",
        "            print(f\"‚ùå PDF file not found: {pdf_path}\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            # Load PDF\n",
        "            print(\"üìÑ Processing PDF document...\")\n",
        "            loader = PyPDFLoader(pdf_path)\n",
        "            docs = loader.load()\n",
        "\n",
        "            # Add comprehensive metadata\n",
        "            for i, doc in enumerate(docs):\n",
        "                doc.metadata.update({\n",
        "                    'source_file': self.pdf_file,\n",
        "                    'domain': 'marine_science',\n",
        "                    'document_type': 'unified_research',\n",
        "                    'page_number': i + 1,\n",
        "                    'total_pages': len(docs)\n",
        "                })\n",
        "\n",
        "            self.documents = docs\n",
        "\n",
        "            # Document analysis\n",
        "            total_chars = sum(len(doc.page_content) for doc in docs)\n",
        "            avg_chars_per_page = total_chars // len(docs) if docs else 0\n",
        "\n",
        "            print(f\"‚úÖ Successfully loaded unified document!\")\n",
        "            print(f\"üìä Document Statistics:\")\n",
        "            print(f\"   ‚Ä¢ Total pages: {len(docs)}\")\n",
        "            print(f\"   ‚Ä¢ Total characters: {total_chars:,}\")\n",
        "            print(f\"   ‚Ä¢ Average chars per page: {avg_chars_per_page:,}\")\n",
        "            print(f\"   ‚Ä¢ Estimated reading time: {total_chars // 1000} minutes\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading {self.pdf_file}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def create_vector_database(self):\n",
        "        \"\"\"Create FAISS vector database from unified marine document\"\"\"\n",
        "        print(\"\\nüß† Creating marine knowledge vector database from unified data...\")\n",
        "\n",
        "        if not self.documents:\n",
        "            print(\"‚ùå No documents loaded. Run load_unified_document() first.\")\n",
        "            return False\n",
        "\n",
        "        # Advanced text splitting optimized for research documents\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1200,  # Optimal size for research content\n",
        "            chunk_overlap=400,  # High overlap for context continuity\n",
        "            separators=[\n",
        "                \"\\n\\n\\n\",  # Major section breaks\n",
        "                \"\\n\\n\",    # Paragraph breaks\n",
        "                \"\\n\",      # Line breaks\n",
        "                \". \",      # Sentence endings\n",
        "                \"! \",      # Exclamation endings\n",
        "                \"? \",      # Question endings\n",
        "                \"; \",      # Semicolon breaks\n",
        "                \", \",      # Comma breaks\n",
        "                \" \",       # Word boundaries\n",
        "                \"\"         # Character level\n",
        "            ],\n",
        "            keep_separator=True,\n",
        "            length_function=len\n",
        "        )\n",
        "\n",
        "        print(\"‚úÇÔ∏è Splitting unified document into knowledge chunks...\")\n",
        "        text_chunks = text_splitter.split_documents(self.documents)\n",
        "\n",
        "        # Add chunk metadata\n",
        "        for i, chunk in enumerate(text_chunks):\n",
        "            chunk.metadata.update({\n",
        "                'chunk_id': i,\n",
        "                'chunk_size': len(chunk.page_content),\n",
        "                'source_type': 'unified_marine_research'\n",
        "            })\n",
        "\n",
        "        print(f\"üìù Created {len(text_chunks)} knowledge chunks\")\n",
        "\n",
        "        # Analyze chunk distribution\n",
        "        chunk_sizes = [len(chunk.page_content) for chunk in text_chunks]\n",
        "        avg_chunk_size = sum(chunk_sizes) // len(chunk_sizes)\n",
        "\n",
        "        print(f\"üìä Chunk Statistics:\")\n",
        "        print(f\"   ‚Ä¢ Total chunks: {len(text_chunks)}\")\n",
        "        print(f\"   ‚Ä¢ Average chunk size: {avg_chunk_size} characters\")\n",
        "        print(f\"   ‚Ä¢ Min chunk size: {min(chunk_sizes)}\")\n",
        "        print(f\"   ‚Ä¢ Max chunk size: {max(chunk_sizes)}\")\n",
        "\n",
        "        # Create embeddings with marine-optimized model\n",
        "        print(\"üî§ Creating semantic embeddings...\")\n",
        "        embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "            model_kwargs={'device': 'cpu'},\n",
        "            encode_kwargs={'normalize_embeddings': True}\n",
        "        )\n",
        "\n",
        "        # Create vector store with metadata\n",
        "        print(\"üóÑÔ∏è Building FAISS vector database...\")\n",
        "        self.vectorstore = FAISS.from_documents(text_chunks, embeddings)\n",
        "\n",
        "        # Save vector store\n",
        "        vectorstore_file = os.path.join(self.vectorstore_path, \"unified_marine_vectorstore\")\n",
        "        self.vectorstore.save_local(vectorstore_file)\n",
        "\n",
        "        print(f\"üíæ Vector database saved to: {vectorstore_file}\")\n",
        "        print(\"‚úÖ Unified marine knowledge database created successfully!\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def setup_qa_chain(self):\n",
        "        \"\"\"Setup QA chain with enhanced marine-specific prompting\"\"\"\n",
        "        print(\"\\nüîó Setting up unified marine expertise QA chain...\")\n",
        "\n",
        "        if not self.llm:\n",
        "            print(\"‚ùå LLM not initialized. Run setup_llm() first.\")\n",
        "            return False\n",
        "\n",
        "        if not self.vectorstore:\n",
        "            print(\"‚ùå Vector store not created. Run create_vector_database() first.\")\n",
        "            return False\n",
        "\n",
        "        # Enhanced marine-specific prompt template\n",
        "        marine_prompt = PromptTemplate(\n",
        "            input_variables=[\"context\", \"question\"],\n",
        "            template=\"\"\"You are a Marine Biodiversity and Ocean Conservation AI Expert with comprehensive knowledge from unified marine research data covering:\n",
        "\n",
        "üåä EXPERTISE AREAS:\n",
        "‚Ä¢ AI Applications in Ocean Conservation & Marine Research\n",
        "‚Ä¢ Advanced Aquaculture Technologies & Precision Farming\n",
        "‚Ä¢ Marine Ecosystem Monitoring & Data Integration\n",
        "‚Ä¢ Sustainable Fisheries Management & Conservation\n",
        "‚Ä¢ Species Identification & Biodiversity Assessment\n",
        "‚Ä¢ Ocean Data Science & GIS Applications\n",
        "\n",
        "üìö RESEARCH CONTEXT:\n",
        "{context}\n",
        "\n",
        "‚ùì USER QUESTION: {question}\n",
        "\n",
        "üéØ EXPERT RESPONSE GUIDELINES:\n",
        "1. Provide scientifically accurate, detailed answers based on the unified research data\n",
        "2. Include specific examples, technologies, and methodologies when relevant\n",
        "3. Explain practical applications and real-world implementations\n",
        "4. Discuss current trends and future opportunities in marine AI\n",
        "5. Reference specific techniques, tools, or approaches mentioned in the research\n",
        "6. If the question goes beyond the research scope, clearly indicate this and provide general marine science guidance\n",
        "\n",
        "üî¨ RESPONSE FORMAT:\n",
        "‚Ä¢ Start with a clear, direct answer\n",
        "‚Ä¢ Provide detailed explanations with technical depth when appropriate\n",
        "‚Ä¢ Include practical examples and applications\n",
        "‚Ä¢ Mention relevant technologies, methods, or approaches\n",
        "‚Ä¢ Discuss implications and future directions\n",
        "\n",
        "DETAILED ANSWER:\"\"\"\n",
        "        )\n",
        "\n",
        "        # Create enhanced QA chain\n",
        "        self.qa_chain = RetrievalQA.from_chain_type(\n",
        "            llm=self.llm,\n",
        "            chain_type=\"stuff\",\n",
        "            retriever=self.vectorstore.as_retriever(\n",
        "                search_type=\"similarity\",\n",
        "                search_kwargs={\"k\": 5}  # Retrieve top 5 most relevant chunks\n",
        "            ),\n",
        "            return_source_documents=True,\n",
        "            chain_type_kwargs={\"prompt\": marine_prompt}\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ Enhanced marine expertise QA chain ready!\")\n",
        "        return True\n",
        "\n",
        "    def ask_marine_question(self, question: str):\n",
        "        \"\"\"Ask a question to the unified marine AI expert\"\"\"\n",
        "        if not self.qa_chain:\n",
        "            return {\n",
        "                \"answer\": \"‚ùå QA chain not initialized. Please run the full setup first.\",\n",
        "                \"sources\": [],\n",
        "                \"confidence\": \"low\"\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            print(f\"üîç Analyzing question: {question}\")\n",
        "\n",
        "            # Get response from QA chain\n",
        "            result = self.qa_chain({\"query\": question})\n",
        "\n",
        "            # Extract and analyze source information\n",
        "            sources = []\n",
        "            for i, doc in enumerate(result[\"source_documents\"]):\n",
        "                source_info = {\n",
        "                    \"chunk_id\": i + 1,\n",
        "                    \"file\": doc.metadata.get(\"source_file\", \"unified_data.pdf\"),\n",
        "                    \"page\": doc.metadata.get(\"page\", \"Unknown\"),\n",
        "                    \"content_preview\": doc.page_content[:250] + \"...\",\n",
        "                    \"relevance_score\": f\"Top {i+1}\"\n",
        "                }\n",
        "                sources.append(source_info)\n",
        "\n",
        "            # Determine confidence based on source quality\n",
        "            confidence = \"high\" if len(result[\"source_documents\"]) >= 3 else \"medium\"\n",
        "\n",
        "            return {\n",
        "                \"answer\": result[\"result\"],\n",
        "                \"sources\": sources,\n",
        "                \"confidence\": confidence,\n",
        "                \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                \"source_document\": \"unified_data.pdf\"\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"answer\": f\"‚ö†Ô∏è Error processing question: {str(e)}\",\n",
        "                \"sources\": [],\n",
        "                \"confidence\": \"low\"\n",
        "            }\n",
        "\n",
        "    def get_training_summary(self):\n",
        "        \"\"\"Get comprehensive summary of unified training data\"\"\"\n",
        "        total_pages = len(self.documents) if self.documents else 0\n",
        "        total_content = sum(len(doc.page_content) for doc in self.documents) if self.documents else 0\n",
        "\n",
        "        return {\n",
        "            \"source_document\": \"unified_data.pdf\",\n",
        "            \"pages_processed\": total_pages,\n",
        "            \"total_characters\": total_content,\n",
        "            \"estimated_tokens\": total_content // 4,  # Rough estimate\n",
        "            \"vector_database\": \"FAISS with sentence-transformers/all-MiniLM-L6-v2\",\n",
        "            \"llm_model\": \"Ollama Llama 3.2 3B\",\n",
        "            \"expertise_areas\": list(self.marine_expertise.keys()),\n",
        "            \"knowledge_domains\": len(self.marine_expertise),\n",
        "            \"status\": \"Ready for comprehensive marine science questions\",\n",
        "            \"capabilities\": [\n",
        "                \"Marine AI applications analysis\",\n",
        "                \"Aquaculture technology guidance\",\n",
        "                \"Conservation strategy recommendations\",\n",
        "                \"Ocean monitoring insights\",\n",
        "                \"Sustainability best practices\",\n",
        "                \"Data science methodologies\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "print(\"üåä Unified Marine Biodiversity Chatbot class defined!\")\n",
        "print(\"üöÄ Ready for single PDF training and deployment!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c522a5cadf0b46e0b7f67aa760e56d3e",
            "688414eed44a42f68be66f6034158f8d",
            "aef44a0386db48bfa106d6a46b704b08",
            "9cedd375484d41ed924d5ded708b0bba",
            "344a16b1a7e34747b179bc95d7b5bb2a",
            "e91c359cc7914a2d9ad85b6ce71854a8",
            "066717c0e0744e91b5fc218381be235f",
            "54a8e03aba374ecb8de7ec1f217d1ecd",
            "b62de217554f4d1fa1b63f6c65c88ace",
            "ad74fd057b334d4bacb1284b68b26b2a",
            "cac8db10d20949e2a60e2caf63183841",
            "cb074c2cad4e46f8901f8b822ab022a3",
            "4809d29e1b594676979f559bc47e7321",
            "af0402434ce84b50aa6f613e8e569662",
            "106d394130e34ffdbe5249eb32c0ef77",
            "1008c9750bc74a7d847c20b2e2caffb9",
            "8c5f4fd0703942cea405358b5ee86365",
            "7d055de0b93841aaa47301f06f88e024",
            "8876892c87ea4a62b23c5332bac0a02e",
            "dbd3a88c62014cbd9ffc63c0516d176d",
            "34a5d39fe1a04544aeb29b5a77bf2716",
            "3115fb7099e146b9a8d5155cd8d5a6f4",
            "b29f39851a104709b295d660d8a41eee",
            "e3edf700ebc34a4db7564e13345d380c",
            "88436314c0914ad190c89e79d73a4c35",
            "4aa64bbd563c436b8866b9fedd6b1341",
            "fa36184e1ef04ecfa1ecaf3aec9adbb8",
            "425d11e7a5814d0c96a4e51a95323399",
            "3ca56633bc784ad1a3932c06c9a39fc1",
            "6096e8eb37ef4239a8552cb7598ee600",
            "1ffe6bff2a55469daffcd143a8482455",
            "a10ec537a726460d87bc287ca9d34e6c",
            "cfebc1fb779c4d5c90cedb9f336ea6b2",
            "5f42007e9ede48faba72eb86e1c8b759",
            "3bfb28c7483b4e4690d4f2b2229ab184",
            "18fb5a6eed394731880327de8bd9d54d",
            "e347f31896824e9dafd7a2cea0e64e30",
            "659ddd06371f4fe8ba0fdb4de83d558c",
            "4df7169451284cadb849bb75f37394df",
            "c999db4eebb349739744ca4b187e4727",
            "883fbe31840f4e53b66946c4aff12de6",
            "4753c515009a42fab226de83517e0186",
            "52bc91c73c93408eb6d3ce4a5f2c3e70",
            "8bf4f5b6d14a4d6f824883754e45b30b",
            "5e9ed78845a3439ab2004185de96c738",
            "1b9b77ee12dc419381e531ce25ffe385",
            "55a8679f3bb14c27bb5f05f5fd10cd5c",
            "4c32a8c3e63c46daaf3aee34188c274a",
            "e00833a7c63d4af7824a0012ab95d467",
            "9628de1ae5bd4e1e9a39f2a63999afac",
            "75a7bee87e5b44b29cc23440ad9812a3",
            "ba325d9e2f8949e8a1208f570d5347d2",
            "2542d37312dc4e9d9e5e6c4351a5b618",
            "9da54dea09fa46a4bce2d238de4bcdc1",
            "fe448548cbcc41bc9d6543c38e15796d",
            "7be907e2be9b4d34bd2b971d137376ae",
            "ea2d76bfa6e947e499e888db15942001",
            "8f08d73e45ae4e8c87077571b0a5585b",
            "daf4e50455984651a74c91f7879a4938",
            "382f3189a52946ec8de9f2bbebb86f77",
            "26ebb50e0b084c888bbf8b0fbbdec8b5",
            "26fd448b36f34b3f8cbdf3cb2196c35a",
            "5f40d467e0cc4d829dd5d4e185c9d230",
            "a5d90d8c85c0452da4722dc9d170afc2",
            "1e3eb3c2c76842afb0931826d9ea7576",
            "c152599403704a5fb30ee4a9200496af",
            "3f61716bdde84247ae19f2bfbe1d18a2",
            "d5c190b85bb349c7811f96df43eadf82",
            "b1b6ab133a064f25afc75f6810e2e16b",
            "728d66626a8c4dcc90cdb72eb3a51a90",
            "f388a98a28ae496597e62f7ad333706b",
            "9418012517664dd99b97b41a3a62599f",
            "db3e8c81304b4cf1b0af186cd3f452a6",
            "10f9de9d5f3c4426a92218ebc09d0922",
            "55eac62490a44156b690063add335234",
            "e048d59e32894c5e98b01b4f4d5d8350",
            "7ff522f4fddc4bf7b7b1f3a85d7157ea",
            "a2d874ad26344981a9054120e9abb8b7",
            "3446ad167ffa497b90de580ec69585e2",
            "d9cf0afe718c4ca7a9b47ac4101ebb9a",
            "de296a25aa004cdd996787d438d4105d",
            "1ea8e8a9aeba4480bece634a0f16b3cd",
            "713cf146006b4ed4bc5c64cc19c3f653",
            "50e8289a0cc34824b6c56d9232107265",
            "eb4c1ba5915947d2835f870543987510",
            "b42ae7b68d00467e91ee97d7085a768d",
            "b4f924740b2f48238f3e1167bc31c29f",
            "25686034010542959aec70df912884d2",
            "b0eb4a8190d541b4b78fa6b57a4bf21e",
            "bfa9fb854f9f44b394254b6952dd8188",
            "eb4e16c2ccbd4156a7fae28e2c242e83",
            "cdab7c65f62e4323aa4a4c3cd8ed1cfc",
            "629c3f8227bf4f928324697ed94ab4b0",
            "889138c2a3bd4740b36a4f9b1c71492f",
            "606c3cdebb5e4b7ea8034e89d5a20806",
            "83a6bd96e8af44f494f3159c6b21723c",
            "0587c16aa5594a2790547dcae1602481",
            "f19e36c03a744299815babaa1b82a650",
            "8c9cf1f9961f4feba64488cb452fd6d1",
            "e4d97fe631de40e79d04259b424baaba",
            "0cb6d5ce24ee4861a1c9b393baa03507",
            "ff80f17e9c53428081d5a9fc927e8766",
            "aed2c0c863b14256bbec85f2bf47d063",
            "eb4ca1a24e4f41f6bb8c0886d17929c1",
            "5ab792cd6a7f4598a394eaf810ecf36e",
            "99b854ec2b9d4a65a0dd17884f02cf49",
            "0552dfa5a7e04598ad75a5f791c94386",
            "2dc010fcfeb94154adf4fcff78b8c487",
            "ec4c9dc6bd2f47c5b3a02051c6eeb952",
            "dfb3ed7822d5402d8418dafc00d625ad",
            "140d67a8ca6b4cd3ba154182857d93a1",
            "411b54a9d1374a7aaee8a2915b2034ce",
            "3258664961e344a8b52243e2987b4620",
            "ae7fdc0090ce43f2b8e59e989f81851a",
            "8482b516df494618b06be9513f5b7816",
            "d72b882449fa46918ccfbec6b2f0255e",
            "1d98fc70ff7f4a67b1a4695e19dd8f2c",
            "e104576692a04f1abe0895f5b3b799be",
            "db8b1c94c02440dfb0343cff6e848e36",
            "b3e5057c5cf642b89e1ce2e5caa61b22",
            "fb0d0371be1446388918aca49951dfa8"
          ]
        },
        "id": "u1NlmiMJFPHD",
        "outputId": "50036240-6a56-47fc-d997-d6342d09f0d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üåä STARTING UNIFIED MARINE CHATBOT TRAINING PIPELINE\n",
            "======================================================================\n",
            "üåä Marine Biodiversity Chatbot initialized!\n",
            "üìÅ PDF Directory: /content/marine_data\n",
            "üìÑ Target PDF: unified_data.pdf\n",
            "üíæ Vector Store: /content/vectorstore\n",
            "\n",
            "ü¶ô STEP 1: Setting up Llama 3.2 3B model...\n",
            "ü¶ô Setting up Llama 3.2 3B model...\n",
            "‚úÖ Llama 3.2 3B model ready!\n",
            "üß™ Test response preview: Artificial intelligence (AI) is being increasingly applied in marine science to advance our understanding of the ocean and its ecosystems. Some exampl...\n",
            "‚úÖ Llama 3.2 3B ready for marine expertise!\n",
            "\n",
            "üìö STEP 2: Loading unified marine research document...\n",
            "\n",
            "üìö Loading unified marine research document: unified_data.pdf\n",
            "üìÑ Processing PDF document...\n",
            "‚úÖ Successfully loaded unified document!\n",
            "üìä Document Statistics:\n",
            "   ‚Ä¢ Total pages: 3208\n",
            "   ‚Ä¢ Total characters: 6,411,049\n",
            "   ‚Ä¢ Average chars per page: 1,998\n",
            "   ‚Ä¢ Estimated reading time: 6411 minutes\n",
            "‚úÖ Unified marine research data loaded successfully!\n",
            "\n",
            "üß† STEP 3: Creating unified marine knowledge vector database...\n",
            "\n",
            "üß† Creating marine knowledge vector database from unified data...\n",
            "‚úÇÔ∏è Splitting unified document into knowledge chunks...\n",
            "üìù Created 8364 knowledge chunks\n",
            "üìä Chunk Statistics:\n",
            "   ‚Ä¢ Total chunks: 8364\n",
            "   ‚Ä¢ Average chunk size: 953 characters\n",
            "   ‚Ä¢ Min chunk size: 2\n",
            "   ‚Ä¢ Max chunk size: 1200\n",
            "üî§ Creating semantic embeddings...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2769032278.py:186: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c522a5cadf0b46e0b7f67aa760e56d3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb074c2cad4e46f8901f8b822ab022a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b29f39851a104709b295d660d8a41eee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f42007e9ede48faba72eb86e1c8b759",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e9ed78845a3439ab2004185de96c738",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7be907e2be9b4d34bd2b971d137376ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f61716bdde84247ae19f2bfbe1d18a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2d874ad26344981a9054120e9abb8b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0eb4a8190d541b4b78fa6b57a4bf21e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4d97fe631de40e79d04259b424baaba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "140d67a8ca6b4cd3ba154182857d93a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üóÑÔ∏è Building FAISS vector database...\n",
            "üíæ Vector database saved to: /content/vectorstore/unified_marine_vectorstore\n",
            "‚úÖ Unified marine knowledge database created successfully!\n",
            "‚úÖ Unified marine knowledge database created!\n",
            "\n",
            "üîó STEP 4: Setting up unified marine expertise QA chain...\n",
            "\n",
            "üîó Setting up unified marine expertise QA chain...\n",
            "‚úÖ Enhanced marine expertise QA chain ready!\n",
            "‚úÖ Unified marine AI expert QA chain ready!\n",
            "\n",
            "üéâ UNIFIED MARINE CHATBOT TRAINING COMPLETED SUCCESSFULLY!\n",
            "======================================================================\n",
            "\n",
            "üìä COMPREHENSIVE TRAINING SUMMARY:\n",
            "   ‚Ä¢ Source Document: unified_data.pdf\n",
            "   ‚Ä¢ Pages Processed: 3208\n",
            "   ‚Ä¢ Total Characters: 6,411,049\n",
            "   ‚Ä¢ Estimated Tokens: 1,602,762\n",
            "   ‚Ä¢ Vector Database: FAISS with sentence-transformers/all-MiniLM-L6-v2\n",
            "   ‚Ä¢ LLM Model: Ollama Llama 3.2 3B\n",
            "   ‚Ä¢ Knowledge Domains: 6\n",
            "   ‚Ä¢ Status: Ready for comprehensive marine science questions\n",
            "\n",
            "üéØ CAPABILITIES:\n",
            "   ‚Ä¢ Marine AI applications analysis\n",
            "   ‚Ä¢ Aquaculture technology guidance\n",
            "   ‚Ä¢ Conservation strategy recommendations\n",
            "   ‚Ä¢ Ocean monitoring insights\n",
            "   ‚Ä¢ Sustainability best practices\n",
            "   ‚Ä¢ Data science methodologies\n",
            "\n",
            "üåä Your Unified Marine Biodiversity AI Expert is ready!\n"
          ]
        }
      ],
      "source": [
        "# Complete training pipeline for Unified Marine Biodiversity Chatbot\n",
        "print(\"üåä STARTING UNIFIED MARINE CHATBOT TRAINING PIPELINE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Initialize chatbot\n",
        "marine_bot = MarineBiodiversityChatbot()\n",
        "\n",
        "# Step 1: Setup Llama 3.2 3B model\n",
        "print(\"\\nü¶ô STEP 1: Setting up Llama 3.2 3B model...\")\n",
        "if marine_bot.setup_llm():\n",
        "    print(\"‚úÖ Llama 3.2 3B ready for marine expertise!\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to setup Llama model. Check Ollama installation.\")\n",
        "    raise Exception(\"LLM setup failed\")\n",
        "\n",
        "# Step 2: Load unified marine research document\n",
        "print(\"\\nüìö STEP 2: Loading unified marine research document...\")\n",
        "if marine_bot.load_unified_document():\n",
        "    print(\"‚úÖ Unified marine research data loaded successfully!\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to load unified_data.pdf. Check file path.\")\n",
        "    raise Exception(\"Document loading failed\")\n",
        "\n",
        "# Step 3: Create vector database\n",
        "print(\"\\nüß† STEP 3: Creating unified marine knowledge vector database...\")\n",
        "if marine_bot.create_vector_database():\n",
        "    print(\"‚úÖ Unified marine knowledge database created!\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to create vector database.\")\n",
        "    raise Exception(\"Vector database creation failed\")\n",
        "\n",
        "# Step 4: Setup QA chain\n",
        "print(\"\\nüîó STEP 4: Setting up unified marine expertise QA chain...\")\n",
        "if marine_bot.setup_qa_chain():\n",
        "    print(\"‚úÖ Unified marine AI expert QA chain ready!\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to setup QA chain.\")\n",
        "    raise Exception(\"QA chain setup failed\")\n",
        "\n",
        "# Training completion\n",
        "print(\"\\nüéâ UNIFIED MARINE CHATBOT TRAINING COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Display comprehensive training summary\n",
        "summary = marine_bot.get_training_summary()\n",
        "print(\"\\nüìä COMPREHENSIVE TRAINING SUMMARY:\")\n",
        "print(f\"   ‚Ä¢ Source Document: {summary['source_document']}\")\n",
        "print(f\"   ‚Ä¢ Pages Processed: {summary['pages_processed']}\")\n",
        "print(f\"   ‚Ä¢ Total Characters: {summary['total_characters']:,}\")\n",
        "print(f\"   ‚Ä¢ Estimated Tokens: {summary['estimated_tokens']:,}\")\n",
        "print(f\"   ‚Ä¢ Vector Database: {summary['vector_database']}\")\n",
        "print(f\"   ‚Ä¢ LLM Model: {summary['llm_model']}\")\n",
        "print(f\"   ‚Ä¢ Knowledge Domains: {summary['knowledge_domains']}\")\n",
        "print(f\"   ‚Ä¢ Status: {summary['status']}\")\n",
        "\n",
        "print(f\"\\nüéØ CAPABILITIES:\")\n",
        "for capability in summary['capabilities']:\n",
        "    print(f\"   ‚Ä¢ {capability}\")\n",
        "\n",
        "print(f\"\\nüåä Your Unified Marine Biodiversity AI Expert is ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pthiGb8fKLLM",
        "outputId": "e9333b7c-afb5-4a97-a5ef-f2f9119fe192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ TESTING UNIFIED MARINE BIODIVERSITY AI EXPERT\n",
            "======================================================================\n",
            "üîß Checking Ollama server status...\n",
            "‚ùå Ollama server not accessible: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/tags (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7c71173c1d60>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "üîÑ Restarting Ollama server...\n",
            "‚úÖ Ollama server restarted successfully!\n",
            "üìã Running 8 comprehensive tests on unified data...\n",
            "======================================================================\n",
            "\n",
            "üî¨ TEST 1: How does AI optimize fish feeding schedules in aquaculture systems?\n",
            "------------------------------------------------------------------------------------------\n",
            "üîç [Attempt 1] Analyzing question: How does AI optimize fish feeding schedules in aquaculture systems?\n",
            "üîç Analyzing question: How does AI optimize fish feeding schedules in aquaculture systems?\n",
            "‚úÖ TEST STATUS: SUCCESS\n",
            "ü§ñ UNIFIED MARINE AI EXPERT RESPONSE:\n",
            "üêüüí° AI optimization of fish feeding schedules in aquaculture systems is a critical aspect of sustainable aquaculture practices. By leveraging advanced machine learning (ML) algorithms, sensor networks, and data analytics, AI can analyze multifaceted datasets, including fish behavior, water quality metrics, and environmental parameters, to deliver precise feeding interventions.\n",
            "\n",
            "The optimization process typically involves the following steps:\n",
            "\n",
            "1. **Data Collection**: Gathering real-time data on fish growth rates, feed consumption, water quality, and other relevant factors using sensors, cameras, and other monitoring systems.\n",
            "2. **Data Analysis**: Applying ML algorithms to analyze the collected data, identifying patterns and trends that can inform feeding strategies.\n",
            "3. **Feeding Scheduling**: Using the insights gained from data analysis, AI enables the creation of personalized feeding schedules tailored to each species' specific needs, growth rates, and nutritional requirements.\n",
            "4. **Real-time Monitoring**: Continuously monitoring fish behavior, water quality, and other factors in real-time, allowing for adjustments to be made as needed.\n",
            "\n",
            "Technologies like computer vision, machine learning, and sensor networks play a crucial role in this process. For instance:\n",
            "\n",
            "* Computer vision can analyze images of fish to detect signs of stress, disease, or nutritional deficiencies.\n",
            "* Machine learning algorithms can identify patterns in feed consumption data to optimize feeding schedules.\n",
            "* Sensor networks can provide real-time monitoring of water quality parameters, such as pH, temperature, and oxygen levels.\n",
            "\n",
            "Practical applications of AI-optimized fish feeding schedules include:\n",
            "\n",
            "* Reduced feed wastage: By optimizing feeding schedules, aquaculture systems can minimize excess feed consumption, reducing waste and associated environmental impacts.\n",
            "* Improved growth rates: Personalized feeding strategies can lead to faster growth rates, increased yields, and enhanced product quality.\n",
            "* Enhanced fish welfare: AI-optimized feeding schedules can help reduce stress and improve overall well-being among farmed fish.\n",
            "\n",
            "Current trends in marine AI include the integration of edge computing, IoT devices, and cloud-based analytics platforms to further enhance the efficiency and effectiveness of AI-driven aquaculture systems. Future opportunities may involve exploring new applications of AI in aquaculture, such as predictive maintenance, disease detection, and more.\n",
            "\n",
            "References:\n",
            "\n",
            "* An et al. (2021). Artificial intelligence for aquaculture: A review.\n",
            "* Feng et al. (2022). Machine learning-based optimization of fish feeding strategies in aquaculture.\n",
            "* Atoum et al. (2015). Feeding automation in aquaculture: A review.\n",
            "\n",
            "Please note that this response is based\n",
            "\n",
            "üìö Knowledge Sources from unified_data.pdf:\n",
            "   ‚Ä¢ Total references: 5\n",
            "   1. Page: 1092 | Relevance: Top 1\n",
            "   2. Page: 942 | Relevance: Top 2\n",
            "   3. Page: 990 | Relevance: Top 3\n",
            "   4. Page: 927 | Relevance: Top 4\n",
            "   5. Page: 975 | Relevance: Top 5\n",
            "   ‚Ä¢ Unique pages referenced: 1092, 975, 942, 990, 927\n",
            "\n",
            "‚úÖ Confidence: high\n",
            "üìÑ Source: unified_data.pdf\n",
            "‚è∞ Generated: 2025-09-11 23:44:56\n",
            "==========================================================================================\n",
            "\n",
            "üî¨ TEST 2: What computer vision techniques are used for marine species identification?\n",
            "------------------------------------------------------------------------------------------\n",
            "üîç [Attempt 1] Analyzing question: What computer vision techniques are used for marine species identification?\n",
            "üîç Analyzing question: What computer vision techniques are used for marine species identification?\n",
            "‚úÖ TEST STATUS: SUCCESS\n",
            "ü§ñ UNIFIED MARINE AI EXPERT RESPONSE:\n",
            "The computer vision techniques used for marine species identification include:\n",
            "\n",
            "1. **Convolutional Neural Networks (CNNs)**: CNNs have been widely adopted in marine species identification due to their ability to automatically detect and classify objects, such as fish, from images and videos. These networks are particularly effective when trained on large datasets of labeled images and can learn to recognize subtle patterns and features that distinguish between different species.\n",
            "2. **Transfer Learning**: Transfer learning involves using pre-trained CNNs as a starting point for training new models on smaller datasets specific to marine species identification. This approach leverages the knowledge gained from the pre-training process, allowing the model to adapt quickly to new data and improve its performance.\n",
            "3. **Object Detection Algorithms**: Object detection algorithms, such as YOLO (You Only Look Once) or SSD (Single Shot Detector), can be used to detect specific objects within images or videos, such as fish or other marine animals. These algorithms are often combined with CNNs to enhance the accuracy of species identification.\n",
            "4. **Image Segmentation**: Image segmentation involves dividing an image into its constituent parts, allowing for the detection and classification of specific features or objects. This technique is particularly useful in marine species identification, where it can be used to identify specific species based on their morphological characteristics.\n",
            "5. **Deep Learning Architectures**: Deep learning architectures, such as U-Net or ResNet, have been explored for marine species identification due to their ability to learn complex patterns and features from images and videos.\n",
            "\n",
            "Practical applications of these techniques include:\n",
            "\n",
            "1. **Automated Species Identification**: AI-powered computer vision can be used to automatically identify species in real-time, allowing for rapid monitoring and assessment of marine ecosystems.\n",
            "2. **Fisheries Monitoring**: Computer vision-based systems can be deployed on fishing vessels or at sea to monitor catch rates, detect bycatch, and identify species caught.\n",
            "3. **Coral Reef Monitoring**: AI-powered computer vision can be used to monitor coral reefs, detecting changes in reef health, monitoring water quality, and identifying species present.\n",
            "\n",
            "Current trends and future opportunities in marine AI include:\n",
            "\n",
            "1. **Increased Use of Edge Computing**: With the growing need for real-time processing and analysis of large datasets, edge computing is becoming increasingly important for marine AI applications.\n",
            "2. **Integration with Other Technologies**: Marine AI is being integrated with other technologies, such as drones, underwater robots, and satellite imaging, to create more comprehensive monitoring systems.\n",
            "3. **Development of New Algorithms and Models**: Researchers are continually developing new algorithms and models that\n",
            "\n",
            "üìö Knowledge Sources from unified_data.pdf:\n",
            "   ‚Ä¢ Total references: 5\n",
            "   1. Page: 1033 | Relevance: Top 1\n",
            "   2. Page: 1 | Relevance: Top 2\n",
            "   3. Page: 1 | Relevance: Top 3\n",
            "   4. Page: 18 | Relevance: Top 4\n",
            "   5. Page: 1032 | Relevance: Top 5\n",
            "   ‚Ä¢ Unique pages referenced: 1033, 1, 1032, 18\n",
            "\n",
            "‚úÖ Confidence: high\n",
            "üìÑ Source: unified_data.pdf\n",
            "‚è∞ Generated: 2025-09-11 23:45:06\n",
            "==========================================================================================\n",
            "\n",
            "üî¨ TEST 3: How do IoT sensors and AI work together for real-time ocean monitoring?\n",
            "------------------------------------------------------------------------------------------\n",
            "üîç [Attempt 1] Analyzing question: How do IoT sensors and AI work together for real-time ocean monitoring?\n",
            "üîç Analyzing question: How do IoT sensors and AI work together for real-time ocean monitoring?\n",
            "‚úÖ TEST STATUS: SUCCESS\n",
            "ü§ñ UNIFIED MARINE AI EXPERT RESPONSE:\n",
            "üåä IoT sensors and AI work together for real-time ocean monitoring by leveraging the strengths of both technologies. Here's a detailed explanation:\n",
            "\n",
            "**IoT Sensors:**\n",
            "\n",
            "IoT (Internet of Things) sensors are equipped with advanced sensing capabilities, such as acoustic, optical, or chemical sensors, which can detect various oceanic parameters like temperature, salinity, pH, and nutrient levels. These sensors can be deployed in various locations, including coastal areas, open oceans, and even underwater.\n",
            "\n",
            "**AI:**\n",
            "\n",
            "Artificial intelligence (AI) plays a crucial role in processing the vast amounts of data generated by IoT sensors. AI algorithms can analyze the sensor data in real-time, identify patterns, and make predictions about oceanic phenomena like ocean currents, marine life distributions, and climate change impacts.\n",
            "\n",
            "**Real-Time Monitoring:**\n",
            "\n",
            "When IoT sensors are connected to AI systems, they enable real-time monitoring of oceanic parameters. This allows researchers, policymakers, and coastal managers to respond quickly to changes in the ocean environment, such as oil spills, algal blooms, or coastal erosion.\n",
            "\n",
            "**Technologies and Methodologies:**\n",
            "\n",
            "Some key technologies and methodologies used for IoT-AI ocean monitoring include:\n",
            "\n",
            "1. **Machine Learning (ML) algorithms**: ML algorithms like Random Forest, Support Vector Machines (SVM), and Neural Networks can be trained on historical data to predict future oceanic patterns.\n",
            "2. **Deep Learning (DL)**: DL techniques like Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) can analyze large datasets and identify complex patterns in oceanic phenomena.\n",
            "3. **Sensor fusion**: Sensor fusion combines data from multiple sensors to provide a more comprehensive understanding of the ocean environment.\n",
            "4. **Cloud computing**: Cloud computing enables the processing and analysis of vast amounts of sensor data, reducing latency and improving real-time monitoring capabilities.\n",
            "\n",
            "**Practical Applications:**\n",
            "\n",
            "Real-time ocean monitoring using IoT-AI has numerous practical applications:\n",
            "\n",
            "1. **Marine conservation**: Real-time monitoring can help track marine life distributions, detect overfishing, and identify areas in need of conservation.\n",
            "2. **Coastal management**: IoT-AI systems can monitor coastal erosion, storm surges, and flooding, enabling more effective management strategies.\n",
            "3. **Climate change research**: Real-time ocean monitoring can provide insights into climate change impacts on ocean currents, sea level rise, and ocean acidification.\n",
            "\n",
            "**Current Trends and Future Opportunities:**\n",
            "\n",
            "The convergence of IoT and AI in ocean monitoring is an emerging field with significant potential for future growth. Some current trends\n",
            "\n",
            "üìö Knowledge Sources from unified_data.pdf:\n",
            "   ‚Ä¢ Total references: 5\n",
            "   1. Page: 5 | Relevance: Top 1\n",
            "   2. Page: 5 | Relevance: Top 2\n",
            "   3. Page: 1689 | Relevance: Top 3\n",
            "   4. Page: 1613 | Relevance: Top 4\n",
            "   5. Page: 955 | Relevance: Top 5\n",
            "   ‚Ä¢ Unique pages referenced: 5, 1689, 1613, 955\n",
            "\n",
            "‚úÖ Confidence: high\n",
            "üìÑ Source: unified_data.pdf\n",
            "‚è∞ Generated: 2025-09-11 23:45:17\n",
            "==========================================================================================\n",
            "\n",
            "üî¨ TEST 4: What role does AI play in addressing climate change impacts on marine ecosystems?\n",
            "------------------------------------------------------------------------------------------\n",
            "üîç [Attempt 1] Analyzing question: What role does AI play in addressing climate change impacts on marine ecosystems?\n",
            "üîç Analyzing question: What role does AI play in addressing climate change impacts on marine ecosystems?\n",
            "‚úÖ TEST STATUS: SUCCESS\n",
            "ü§ñ UNIFIED MARINE AI EXPERT RESPONSE:\n",
            "AI plays a crucial role in addressing climate change impacts on marine ecosystems by providing predictive insights, monitoring, and analysis of ocean health. Machine learning models can analyze historical data on ocean temperatures, acidity levels, and current flows to forecast changes to habitats and species distributions.\n",
            "\n",
            "For instance, AI-driven models can anticipate the migration patterns of fish populations as they move in response to temperature shifts. These predictions are essential for fisheries management, allowing for proactive strategies that protect both marine biodiversity and the livelihoods of communities dependent on fishing.\n",
            "\n",
            "Moreover, AI excels at predictive modeling and is proving instrumental in forecasting the impact of climate-related changes on marine ecosystems. By analyzing historical data, machine learning models can predict changes to habitats and species distributions, enabling conservationists to make informed decisions about conservation efforts.\n",
            "\n",
            "For example, AI can help track coral health over time, which is crucial in identifying stressed or bleaching corals early. This allows conservationists to make timely interventions, thereby minimizing ecological and economic damage.\n",
            "\n",
            "In addition, AI-powered monitoring systems can detect changes in ocean conditions, such as ocean acidification, and provide real-time alerts for policymakers and researchers. This enables them to respond quickly to emerging issues, ensuring that marine ecosystems receive the necessary attention and protection.\n",
            "\n",
            "Furthermore, AI-driven solutions are being developed to address climate-related pollution in oceans. For instance, machine learning algorithms can be used to identify areas of high pollution and predict the movement of pollutants through ocean currents.\n",
            "\n",
            "Overall, AI is transforming our understanding of climate change impacts on marine ecosystems and enabling us to take proactive measures to protect these vital resources. By leveraging AI technologies, we can make more informed decisions about conservation efforts, fisheries management, and pollution mitigation, ultimately safeguarding the health of our oceans for future generations.\n",
            "\n",
            "üåä\n",
            "\n",
            "üìö Knowledge Sources from unified_data.pdf:\n",
            "   ‚Ä¢ Total references: 5\n",
            "   1. Page: 5 | Relevance: Top 1\n",
            "   2. Page: 2 | Relevance: Top 2\n",
            "   3. Page: 5 | Relevance: Top 3\n",
            "   4. Page: 2 | Relevance: Top 4\n",
            "   5. Page: 0 | Relevance: Top 5\n",
            "   ‚Ä¢ Unique pages referenced: 5, 0, 2\n",
            "\n",
            "‚úÖ Confidence: high\n",
            "üìÑ Source: unified_data.pdf\n",
            "‚è∞ Generated: 2025-09-11 23:45:24\n",
            "==========================================================================================\n",
            "\n",
            "üî¨ TEST 5: How is big data analytics applied to marine biodiversity research?\n",
            "------------------------------------------------------------------------------------------\n",
            "üîç [Attempt 1] Analyzing question: How is big data analytics applied to marine biodiversity research?\n",
            "üîç Analyzing question: How is big data analytics applied to marine biodiversity research?\n",
            "‚úÖ TEST STATUS: SUCCESS\n",
            "ü§ñ UNIFIED MARINE AI EXPERT RESPONSE:\n",
            "Big data analytics plays a crucial role in marine biodiversity research by enabling scientists to analyze and understand complex patterns and trends in large datasets. Here are some ways big data analytics is applied to marine biodiversity research:\n",
            "\n",
            "1. **Species identification and classification**: Big data analytics can be used to identify and classify species based on genetic, morphological, or other characteristics. For example, machine learning algorithms can be trained on large datasets of DNA sequences to identify new species or confirm existing ones.\n",
            "2. **Biodiversity assessment**: Big data analytics can help assess biodiversity by analyzing large datasets of environmental variables such as temperature, salinity, and ocean currents. This information can be used to predict the distribution of species and understand how they respond to changes in their environment.\n",
            "3. **Habitat mapping**: Big data analytics can be used to create detailed maps of marine habitats, including coral reefs, kelp forests, and seagrass beds. These maps can help scientists understand the distribution of species and identify areas that require conservation efforts.\n",
            "4. **Fisheries management**: Big data analytics can be used to analyze catch data, track fish populations, and predict fishing patterns. This information can be used to inform fisheries management decisions and ensure sustainable fishing practices.\n",
            "5. **Climate change research**: Big data analytics can help scientists understand the impacts of climate change on marine ecosystems. By analyzing large datasets of ocean temperature, salinity, and other environmental variables, researchers can identify trends and patterns that inform our understanding of climate change.\n",
            "\n",
            "Technologies used in big data analytics for marine biodiversity research include:\n",
            "\n",
            "1. **Machine learning algorithms**: These algorithms can be trained on large datasets to identify patterns and make predictions.\n",
            "2. **Deep learning techniques**: These techniques can be used to analyze complex datasets, such as those related to species identification or habitat mapping.\n",
            "3. **Geographic information systems (GIS)**: GIS can be used to create detailed maps of marine habitats and track the distribution of species.\n",
            "4. **Cloud computing**: Cloud computing platforms can be used to store and process large datasets, making it easier for researchers to access and analyze data.\n",
            "\n",
            "Some practical applications of big data analytics in marine biodiversity research include:\n",
            "\n",
            "1. **Predicting species distributions**: By analyzing large datasets of environmental variables, scientists can predict the distribution of species and identify areas that require conservation efforts.\n",
            "2. **Identifying new species**: Machine learning algorithms can be trained on large datasets of DNA sequences to identify new species or confirm existing ones.\n",
            "3. **Monitoring marine ecosystems**: Big data analytics can be used to monitor changes in marine\n",
            "\n",
            "üìö Knowledge Sources from unified_data.pdf:\n",
            "   ‚Ä¢ Total references: 5\n",
            "   1. Page: 2329 | Relevance: Top 1\n",
            "   2. Page: 1789 | Relevance: Top 2\n",
            "   3. Page: 847 | Relevance: Top 3\n",
            "   4. Page: 1693 | Relevance: Top 4\n",
            "   5. Page: 846 | Relevance: Top 5\n",
            "   ‚Ä¢ Unique pages referenced: 1693, 846, 847, 2329, 1789\n",
            "\n",
            "‚úÖ Confidence: high\n",
            "üìÑ Source: unified_data.pdf\n",
            "‚è∞ Generated: 2025-09-11 23:45:35\n",
            "==========================================================================================\n",
            "\n",
            "üî¨ TEST 6: What are the latest precision technologies in sustainable aquaculture?\n",
            "------------------------------------------------------------------------------------------\n",
            "üîç [Attempt 1] Analyzing question: What are the latest precision technologies in sustainable aquaculture?\n",
            "üîç Analyzing question: What are the latest precision technologies in sustainable aquaculture?\n",
            "‚úÖ TEST STATUS: SUCCESS\n",
            "ü§ñ UNIFIED MARINE AI EXPERT RESPONSE:\n",
            "The latest precision technologies in sustainable aquaculture include:\n",
            "\n",
            "1. **Precision Farming**: This involves the use of advanced technologies such as drones, satellite imaging, and sensor networks to monitor water quality, temperature, pH, and other parameters in real-time. This data is then used to optimize feeding strategies, reduce waste, and improve overall efficiency (Chiu et al., 2022; Zheng et al., 2023).\n",
            "2. **Artificial Intelligence (AI) and Machine Learning (ML)**: AI and ML algorithms can be trained on large datasets to predict water quality parameters, detect anomalies, and identify patterns in aquaculture systems. This enables real-time monitoring and proactive intervention to prevent harmful conditions such as oxygen depletion or harmful algal blooms (Arepalli and Khetavath, 2023; Arepalli and Naik, 2024).\n",
            "3. **Internet of Things (IoT)**: IoT sensors can be integrated into aquaculture systems to monitor water quality, temperature, and other parameters in real-time. This data can then be used to optimize feeding strategies, reduce waste, and improve overall efficiency (Wang et al., 2020; Zenger et al., 2019).\n",
            "4. **Big Data Analytics**: The use of big data analytics enables the analysis of large datasets from aquaculture systems, providing insights into water quality, fish health, and other parameters. This information can be used to optimize feeding strategies, reduce waste, and improve overall efficiency (Chen et al., 2020b; Chen et al., 2020a).\n",
            "5. **Genomics and Genotyping**: The use of genomics and genotyping techniques enables the identification of genetic markers associated with disease resistance, growth rate, and other traits in aquaculture species. This information can be used to develop more resilient and sustainable aquaculture systems (Islam et al., 2024; Vo et al., 2021).\n",
            "6. **Precision Nutrition**: Precision nutrition involves the use of advanced technologies such as DNA sequencing and machine learning algorithms to optimize feeding strategies for aquaculture species. This approach enables the identification of optimal nutrient profiles, reducing waste and improving overall efficiency (Saberioon et al., 2017; Zhao et al., 2021).\n",
            "\n",
            "These precision technologies have the potential to significantly improve the sustainability and resilience of aquaculture systems, while also reducing environmental impacts and improving economic viability.\n",
            "\n",
            "References:\n",
            "\n",
            "Arepalli, S. K., & Khetavath, R. (\n",
            "\n",
            "üìö Knowledge Sources from unified_data.pdf:\n",
            "   ‚Ä¢ Total references: 5\n",
            "   1. Page: 928 | Relevance: Top 1\n",
            "   2. Page: 976 | Relevance: Top 2\n",
            "   3. Page: 1064 | Relevance: Top 3\n",
            "   4. Page: 1065 | Relevance: Top 4\n",
            "   5. Page: 1083 | Relevance: Top 5\n",
            "   ‚Ä¢ Unique pages referenced: 1064, 976, 1083, 1065, 928\n",
            "\n",
            "‚úÖ Confidence: high\n",
            "üìÑ Source: unified_data.pdf\n",
            "‚è∞ Generated: 2025-09-11 23:45:45\n",
            "==========================================================================================\n",
            "\n",
            "üî¨ TEST 7: How do predictive models help in marine protected area management?\n",
            "------------------------------------------------------------------------------------------\n",
            "üîç [Attempt 1] Analyzing question: How do predictive models help in marine protected area management?\n",
            "üîç Analyzing question: How do predictive models help in marine protected area management?\n",
            "‚úÖ TEST STATUS: SUCCESS\n",
            "ü§ñ UNIFIED MARINE AI EXPERT RESPONSE:\n",
            "Predictive models play a crucial role in marine protected area (MPA) management by providing valuable insights into the dynamics of marine ecosystems, species distributions, and habitat changes. By analyzing historical data on ocean temperatures, acidity levels, and current flows, machine learning models can predict changes to habitats and species distributions, enabling proactive strategies for conservation and sustainable use of marine resources.\n",
            "\n",
            "For instance, AI-driven models can anticipate the migration patterns of fish populations as they respond to temperature shifts, allowing for targeted conservation efforts. These insights are essential for MPA management, as they inform decisions on habitat restoration, species reintroduction, and fisheries management.\n",
            "\n",
            "Moreover, predictive models can help identify areas with high conservation value, such as coral reefs or seagrass beds, which can be protected from human impacts like overfishing or coastal development. By analyzing data on species distributions, habitat connectivity, and ecosystem services, models can provide a framework for MPA design and management.\n",
            "\n",
            "For example, the JSDM (Joint Statistical Data Model) approach, mentioned in the research context, can be used to develop ecological predictions at a local scale (i.e., at the site of real-time measurements) or at a regional scale (i.e., when PTO data are assimilated into oceanographic models). This allows for the validation of model outputs with data collected at observatories, ensuring that MPA management decisions are informed by robust scientific evidence.\n",
            "\n",
            "In addition, predictive models can help track coral health over time, which is crucial in identifying stressed or bleaching corals early. This enables conservationists to make timely interventions, thereby conserving coral populations and maintaining the integrity of MPAs.\n",
            "\n",
            "To leverage these benefits, marine AI researchers and practitioners are exploring new technologies and methodologies, such as:\n",
            "\n",
            "1. Integration of satellite imagery and sensor data for MPA monitoring and management.\n",
            "2. Development of machine learning algorithms that can analyze large datasets on ocean acidification, warming, and other climate change drivers.\n",
            "3. Application of spatial analysis techniques to identify areas with high conservation value and prioritize MPA design.\n",
            "\n",
            "By harnessing the power of predictive models and marine AI, we can enhance our understanding of marine ecosystems, inform effective MPA management strategies, and ultimately conserve marine biodiversity for future generations.\n",
            "\n",
            "References:\n",
            "Ali, S., et al. (2021). \"Predictive modeling of ocean acidification impacts on marine life.\" Journal of Marine Systems, 225, 102966.\n",
            "Pasquetto, A., et al. (2024). \"Data management in marine conservation: Challenges and opportunities.\" Marine Policy\n",
            "\n",
            "üìö Knowledge Sources from unified_data.pdf:\n",
            "   ‚Ä¢ Total references: 5\n",
            "   1. Page: 1053 | Relevance: Top 1\n",
            "   2. Page: 2457 | Relevance: Top 2\n",
            "   3. Page: 2 | Relevance: Top 3\n",
            "   4. Page: 2 | Relevance: Top 4\n",
            "   5. Page: 2329 | Relevance: Top 5\n",
            "   ‚Ä¢ Unique pages referenced: 2457, 1053, 2, 2329\n",
            "\n",
            "‚úÖ Confidence: high\n",
            "üìÑ Source: unified_data.pdf\n",
            "‚è∞ Generated: 2025-09-11 23:45:56\n",
            "==========================================================================================\n",
            "\n",
            "üî¨ TEST 8: How does GIS integration enhance marine research capabilities?\n",
            "------------------------------------------------------------------------------------------\n",
            "üîç [Attempt 1] Analyzing question: How does GIS integration enhance marine research capabilities?\n",
            "üîç Analyzing question: How does GIS integration enhance marine research capabilities?\n",
            "‚úÖ TEST STATUS: SUCCESS\n",
            "ü§ñ UNIFIED MARINE AI EXPERT RESPONSE:\n",
            "GIS integration is a crucial component of marine research capabilities, enhancing the ability to analyze, understand, and manage coastal and marine ecosystems. By leveraging Geographic Information Systems (GIS), researchers can visualize, process, and analyze large datasets related to oceanography, ecology, and conservation.\n",
            "\n",
            "One key benefit of GIS integration in marine research is its ability to provide spatial context and insights into the relationships between different components of a marine ecosystem. For example, using GIS, researchers can:\n",
            "\n",
            "1. **Visualize habitat distribution**: By overlaying maps of coastal habitats, such as mangroves or seagrass beds, with data on species distributions, researchers can identify areas of high conservation value.\n",
            "2. **Analyze ocean currents and circulation patterns**: Using GIS, researchers can create detailed maps of ocean currents and circulation patterns, which is essential for understanding the impacts of climate change on marine ecosystems.\n",
            "3. **Identify areas of high biodiversity**: By analyzing spatial data on species distributions, habitat types, and other environmental factors, researchers can identify areas with high levels of biodiversity.\n",
            "\n",
            "To achieve these goals, researchers often use a range of GIS technologies and methodologies, including:\n",
            "\n",
            "1. **Remote sensing**: Using satellite and airborne imagery to collect data on ocean color, temperature, and other environmental variables.\n",
            "2. **Field observations**: Collecting in-situ data on water quality, sediment characteristics, and other factors using sensors and sampling equipment.\n",
            "3. **Spatial modeling**: Developing mathematical models that simulate the behavior of marine ecosystems and predict the impacts of different management scenarios.\n",
            "\n",
            "Some specific examples of GIS integration in marine research include:\n",
            "\n",
            "1. The use of GIS to inform coastal zone management decisions, such as identifying areas for conservation or restoration.\n",
            "2. The development of spatially explicit models to predict the impacts of climate change on marine ecosystems.\n",
            "3. The creation of online platforms and tools to facilitate public engagement with marine data and research findings.\n",
            "\n",
            "In terms of current trends and future opportunities in marine AI, there is a growing focus on integrating machine learning algorithms with GIS data to improve the accuracy and efficiency of marine research. For example:\n",
            "\n",
            "1. **Deep learning**: Using deep learning techniques to analyze large datasets related to oceanography and ecology.\n",
            "2. **Transfer learning**: Applying pre-trained models to new domains or applications in marine research.\n",
            "3. **Explainable AI**: Developing methods to interpret and explain the decisions made by machine learning models in marine research.\n",
            "\n",
            "Overall, GIS integration is a powerful tool for enhancing marine research capabilities, providing insights into complex ecosystems and informing management decisions that support conservation and sustainable development.\n",
            "\n",
            "üìö Knowledge Sources from unified_data.pdf:\n",
            "   ‚Ä¢ Total references: 5\n",
            "   1. Page: 2339 | Relevance: Top 1\n",
            "   2. Page: 1735 | Relevance: Top 2\n",
            "   3. Page: 2331 | Relevance: Top 3\n",
            "   4. Page: 2330 | Relevance: Top 4\n",
            "   5. Page: 2342 | Relevance: Top 5\n",
            "   ‚Ä¢ Unique pages referenced: 2331, 2339, 2342, 1735, 2330\n",
            "\n",
            "‚úÖ Confidence: high\n",
            "üìÑ Source: unified_data.pdf\n",
            "‚è∞ Generated: 2025-09-11 23:46:06\n",
            "==========================================================================================\n",
            "\n",
            "üìä COMPREHENSIVE TESTING ANALYSIS:\n",
            "==================================================\n",
            "üéØ **Overall Results:**\n",
            "   ‚Ä¢ Total tests run: 8\n",
            "   ‚Ä¢ Successful tests: 8\n",
            "   ‚Ä¢ Failed tests: 0\n",
            "   ‚Ä¢ Success rate: 100.0%\n",
            "\n",
            "üìà **Success Analysis:**\n",
            "   ‚Ä¢ High confidence responses: 8/8\n",
            "   ‚Ä¢ Average sources per response: 5.0\n",
            "   ‚Ä¢ Average response length: 2729 characters\n",
            "   ‚Ä¢ Total knowledge chunks referenced: 40\n",
            "\n",
            "üéâ ALL TESTS COMPLETED SUCCESSFULLY!\n",
            "‚úÖ Your Unified Marine Biodiversity Chatbot is fully functional!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Comprehensive testing of the Unified Marine Biodiversity Chatbot - FIXED VERSION\n",
        "print(\"üß™ TESTING UNIFIED MARINE BIODIVERSITY AI EXPERT\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# First, let's check Ollama server status\n",
        "import requests\n",
        "import time\n",
        "\n",
        "def check_ollama_server():\n",
        "    \"\"\"Check if Ollama server is running properly\"\"\"\n",
        "    try:\n",
        "        response = requests.get('http://localhost:11434/api/tags', timeout=5)\n",
        "        if response.status_code == 200:\n",
        "            print(\"‚úÖ Ollama server is running\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Ollama server issue: Status {response.status_code}\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Ollama server not accessible: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def restart_ollama_if_needed():\n",
        "    \"\"\"Restart Ollama server if needed\"\"\"\n",
        "    if not check_ollama_server():\n",
        "        print(\"üîÑ Restarting Ollama server...\")\n",
        "\n",
        "        # Kill any existing ollama processes\n",
        "        import subprocess\n",
        "        try:\n",
        "            subprocess.run([\"pkill\", \"-f\", \"ollama\"], capture_output=True)\n",
        "            time.sleep(2)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Start Ollama server in background\n",
        "        def start_server():\n",
        "            subprocess.run([\"ollama\", \"serve\"], capture_output=False)\n",
        "\n",
        "        import threading\n",
        "        server_thread = threading.Thread(target=start_server, daemon=True)\n",
        "        server_thread.start()\n",
        "\n",
        "        # Wait for server to start\n",
        "        time.sleep(10)\n",
        "\n",
        "        # Test model availability\n",
        "        try:\n",
        "            test_response = requests.post('http://localhost:11434/api/generate',\n",
        "                                        json={'model': 'llama3.2:3b', 'prompt': 'test', 'stream': False},\n",
        "                                        timeout=30)\n",
        "            if test_response.status_code == 200:\n",
        "                print(\"‚úÖ Ollama server restarted successfully!\")\n",
        "                return True\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Ollama server restart may need more time\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Ollama restart test failed: {e}\")\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Check and restart Ollama if needed\n",
        "print(\"üîß Checking Ollama server status...\")\n",
        "restart_ollama_if_needed()\n",
        "\n",
        "# Enhanced marine chatbot question function with better error handling\n",
        "def safe_ask_marine_question(question: str, max_retries=2):\n",
        "    \"\"\"Ask question with retry mechanism and comprehensive error handling\"\"\"\n",
        "\n",
        "    for attempt in range(max_retries + 1):\n",
        "        try:\n",
        "            print(f\"üîç [Attempt {attempt + 1}] Analyzing question: {question}\")\n",
        "\n",
        "            # Get response from marine chatbot\n",
        "            response = marine_bot.ask_marine_question(question)\n",
        "\n",
        "            # Validate response structure\n",
        "            if not isinstance(response, dict):\n",
        "                response = {\n",
        "                    \"answer\": str(response) if response else \"No response generated\",\n",
        "                    \"sources\": [],\n",
        "                    \"confidence\": \"low\",\n",
        "                    \"source_document\": \"unified_data.pdf\",\n",
        "                    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                }\n",
        "\n",
        "            # Ensure all required keys exist\n",
        "            required_keys = [\"answer\", \"sources\", \"confidence\", \"source_document\", \"timestamp\"]\n",
        "            for key in required_keys:\n",
        "                if key not in response:\n",
        "                    if key == \"answer\":\n",
        "                        response[key] = \"Error: No answer generated\"\n",
        "                    elif key == \"sources\":\n",
        "                        response[key] = []\n",
        "                    elif key == \"confidence\":\n",
        "                        response[key] = \"low\"\n",
        "                    elif key == \"source_document\":\n",
        "                        response[key] = \"unified_data.pdf\"\n",
        "                    elif key == \"timestamp\":\n",
        "                        response[key] = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            # If we got a valid response, return it\n",
        "            if not response[\"answer\"].startswith(\"‚ö†Ô∏è Error\"):\n",
        "                return response\n",
        "\n",
        "            # If it's an error but last attempt, return it anyway\n",
        "            if attempt == max_retries:\n",
        "                return response\n",
        "\n",
        "            # Otherwise, wait and retry\n",
        "            print(f\"‚ö†Ô∏è Attempt {attempt + 1} failed, retrying in 3 seconds...\")\n",
        "            time.sleep(3)\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"‚ö†Ô∏è Error on attempt {attempt + 1}: {str(e)}\"\n",
        "            print(error_msg)\n",
        "\n",
        "            if attempt == max_retries:\n",
        "                # Return error response on final attempt\n",
        "                return {\n",
        "                    \"answer\": f\"‚ùå Failed to process question after {max_retries + 1} attempts. Error: {str(e)}\",\n",
        "                    \"sources\": [],\n",
        "                    \"confidence\": \"low\",\n",
        "                    \"source_document\": \"unified_data.pdf\",\n",
        "                    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                }\n",
        "\n",
        "            # Wait before retry\n",
        "            time.sleep(3)\n",
        "\n",
        "    # Fallback (should not reach here)\n",
        "    return {\n",
        "        \"answer\": \"‚ùå Unexpected error in question processing\",\n",
        "        \"sources\": [],\n",
        "        \"confidence\": \"low\",\n",
        "        \"source_document\": \"unified_data.pdf\",\n",
        "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n",
        "\n",
        "# Comprehensive test questions covering all marine domains\n",
        "test_questions = [\n",
        "    # AI in Aquaculture\n",
        "    \"How does AI optimize fish feeding schedules in aquaculture systems?\",\n",
        "\n",
        "    # Marine Conservation Technology\n",
        "    \"What computer vision techniques are used for marine species identification?\",\n",
        "\n",
        "    # Ocean Monitoring & Data Integration\n",
        "    \"How do IoT sensors and AI work together for real-time ocean monitoring?\",\n",
        "\n",
        "    # Sustainability & Climate Change\n",
        "    \"What role does AI play in addressing climate change impacts on marine ecosystems?\",\n",
        "\n",
        "    # Big Data & Analytics\n",
        "    \"How is big data analytics applied to marine biodiversity research?\",\n",
        "\n",
        "    # Precision Technologies\n",
        "    \"What are the latest precision technologies in sustainable aquaculture?\",\n",
        "\n",
        "    # Conservation Strategies\n",
        "    \"How do predictive models help in marine protected area management?\",\n",
        "\n",
        "    # Technology Integration\n",
        "    \"How does GIS integration enhance marine research capabilities?\"\n",
        "]\n",
        "\n",
        "print(f\"üìã Running {len(test_questions)} comprehensive tests on unified data...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Run comprehensive test suite with error handling\n",
        "test_results = []\n",
        "successful_tests = 0\n",
        "failed_tests = 0\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\nüî¨ TEST {i}: {question}\")\n",
        "    print(\"-\" * 90)\n",
        "\n",
        "    # Get response with error handling\n",
        "    response = safe_ask_marine_question(question)\n",
        "\n",
        "    # Determine if test was successful\n",
        "    is_successful = not response[\"answer\"].startswith((\"‚ö†Ô∏è\", \"‚ùå\"))\n",
        "\n",
        "    if is_successful:\n",
        "        successful_tests += 1\n",
        "        print(\"‚úÖ TEST STATUS: SUCCESS\")\n",
        "    else:\n",
        "        failed_tests += 1\n",
        "        print(\"‚ùå TEST STATUS: FAILED\")\n",
        "\n",
        "    # Display response\n",
        "    print(\"ü§ñ UNIFIED MARINE AI EXPERT RESPONSE:\")\n",
        "    print(response[\"answer\"])\n",
        "\n",
        "    # Show detailed source information (safely)\n",
        "    try:\n",
        "        if response.get(\"sources\") and len(response[\"sources\"]) > 0:\n",
        "            print(f\"\\nüìö Knowledge Sources from {response.get('source_document', 'unified_data.pdf')}:\")\n",
        "            print(f\"   ‚Ä¢ Total references: {len(response['sources'])}\")\n",
        "\n",
        "            # Safely extract page information\n",
        "            pages = []\n",
        "            for j, source in enumerate(response[\"sources\"], 1):\n",
        "                page = source.get('page', 'Unknown')\n",
        "                relevance = source.get('relevance_score', f'Rank {j}')\n",
        "                pages.append(str(page))\n",
        "                print(f\"   {j}. Page: {page} | Relevance: {relevance}\")\n",
        "\n",
        "            # Show unique pages\n",
        "            unique_pages = list(set(pages))\n",
        "            print(f\"   ‚Ä¢ Unique pages referenced: {', '.join(unique_pages)}\")\n",
        "        else:\n",
        "            print(f\"\\nüìö No specific sources retrieved (using general knowledge)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ö†Ô∏è Error displaying sources: {e}\")\n",
        "\n",
        "    # Display metadata safely\n",
        "    print(f\"\\n‚úÖ Confidence: {response.get('confidence', 'unknown')}\")\n",
        "    print(f\"üìÑ Source: {response.get('source_document', 'unified_data.pdf')}\")\n",
        "    print(f\"‚è∞ Generated: {response.get('timestamp', 'unknown')}\")\n",
        "\n",
        "    # Store results for analysis\n",
        "    test_results.append({\n",
        "        \"test_number\": i,\n",
        "        \"question\": question,\n",
        "        \"success\": is_successful,\n",
        "        \"confidence\": response.get('confidence', 'unknown'),\n",
        "        \"sources_count\": len(response.get('sources', [])),\n",
        "        \"response_length\": len(response.get('answer', ''))\n",
        "    })\n",
        "\n",
        "    print(\"=\" * 90)\n",
        "\n",
        "    # Add small delay between tests\n",
        "    time.sleep(1)\n",
        "\n",
        "# Comprehensive test results analysis\n",
        "print(f\"\\nüìä COMPREHENSIVE TESTING ANALYSIS:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"üéØ **Overall Results:**\")\n",
        "print(f\"   ‚Ä¢ Total tests run: {len(test_results)}\")\n",
        "print(f\"   ‚Ä¢ Successful tests: {successful_tests}\")\n",
        "print(f\"   ‚Ä¢ Failed tests: {failed_tests}\")\n",
        "print(f\"   ‚Ä¢ Success rate: {(successful_tests/len(test_results)*100):.1f}%\")\n",
        "\n",
        "if successful_tests > 0:\n",
        "    # Analyze successful tests\n",
        "    successful_results = [r for r in test_results if r['success']]\n",
        "\n",
        "    high_confidence = sum(1 for r in successful_results if r['confidence'] == 'high')\n",
        "    total_sources = sum(r['sources_count'] for r in successful_results)\n",
        "    avg_sources = total_sources / len(successful_results) if successful_results else 0\n",
        "    avg_response_length = sum(r['response_length'] for r in successful_results) / len(successful_results)\n",
        "\n",
        "    print(f\"\\nüìà **Success Analysis:**\")\n",
        "    print(f\"   ‚Ä¢ High confidence responses: {high_confidence}/{successful_tests}\")\n",
        "    print(f\"   ‚Ä¢ Average sources per response: {avg_sources:.1f}\")\n",
        "    print(f\"   ‚Ä¢ Average response length: {avg_response_length:.0f} characters\")\n",
        "    print(f\"   ‚Ä¢ Total knowledge chunks referenced: {total_sources}\")\n",
        "\n",
        "if failed_tests > 0:\n",
        "    print(f\"\\n‚ö†Ô∏è **Failure Analysis:**\")\n",
        "    failed_results = [r for r in test_results if not r['success']]\n",
        "    print(f\"   ‚Ä¢ Failed tests: {[r['test_number'] for r in failed_results]}\")\n",
        "    print(f\"   ‚Ä¢ Common issue: Likely Ollama server connectivity\")\n",
        "\n",
        "    print(f\"\\nüîß **Troubleshooting Suggestions:**\")\n",
        "    print(f\"   ‚Ä¢ Restart the Ollama server (run Cell 2 again)\")\n",
        "    print(f\"   ‚Ä¢ Check system resources (RAM/CPU usage)\")\n",
        "    print(f\"   ‚Ä¢ Verify llama3.2:3b model is downloaded\")\n",
        "    print(f\"   ‚Ä¢ Try testing individual questions manually\")\n",
        "\n",
        "# Final status\n",
        "if successful_tests == len(test_questions):\n",
        "    print(f\"\\nüéâ ALL TESTS COMPLETED SUCCESSFULLY!\")\n",
        "    print(f\"‚úÖ Your Unified Marine Biodiversity Chatbot is fully functional!\")\n",
        "elif successful_tests > len(test_questions) // 2:\n",
        "    print(f\"\\nüî∂ PARTIAL SUCCESS - Most tests passed!\")\n",
        "    print(f\"‚úÖ Your Unified Marine Biodiversity Chatbot is mostly functional!\")\n",
        "    print(f\"üîß Consider addressing connection issues for 100% reliability\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è ISSUES DETECTED - Many tests failed!\")\n",
        "    print(f\"üîß Please check Ollama setup and model availability\")\n",
        "    print(f\"üí° Try rerunning Cell 2 (Ollama setup) and then this cell\")\n",
        "\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrhOKRoGLMTO",
        "outputId": "673f9640-7fcd-4998-bc60-eeeec532b798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåä\n",
            "UNIFIED MARINE BIODIVERSITY AI EXPERT\n",
            "üåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåäüåä\n",
            "\n",
            "ü§ñ Powered by Llama 3.2 3B + Unified Marine Research Dataset\n",
            "üìö Single comprehensive knowledge source: unified_data.pdf\n",
            "\n",
            "üéØ Comprehensive Marine Expertise:\n",
            "   üêü Advanced Aquaculture & Fish Farming Technologies\n",
            "   üåä Marine Conservation & Ecosystem Protection\n",
            "   üìä Ocean Data Science & GIS Integration\n",
            "   üé£ Sustainable Fisheries & Resource Management\n",
            "   üî¨ Species Identification & Biodiversity Monitoring\n",
            "   ü§ñ AI Applications in Marine Science\n",
            "   üå°Ô∏è Climate Change & Ocean Health\n",
            "   üí° Innovation & Future Technologies\n",
            "\n",
            "üí° Example questions for unified dataset:\n",
            "   ‚Ä¢ How does AI revolutionize marine aquaculture operations?\n",
            "   ‚Ä¢ What integrated approaches exist for ocean conservation?\n",
            "   ‚Ä¢ How do predictive models enhance fisheries management?\n",
            "   ‚Ä¢ What role does big data play in marine research?\n",
            "   ‚Ä¢ How are IoT networks transforming ocean monitoring?\n",
            "\n",
            "üìù Commands: Type 'quit' to exit, 'help' for more examples\n",
            "üåä--------------------------------------------------------------------üåä\n",
            "\n",
            "üåä [Session 1] Your marine research question: Hi\n",
            "\n",
            "üîç [Analyzing] Consulting unified marine research database...\n",
            "üîç Analyzing question: Hi\n",
            "\n",
            "ü§ñ UNIFIED MARINE AI EXPERT RESPONSE:\n",
            "------------------------------------------------------------\n",
            "Hello! I'd be happy to help you with your questions about marine biodiversity and ocean conservation. Please go ahead and ask your question, and I'll do my best to provide a detailed and scientifically accurate response.\n",
            "\n",
            "What's on your mind?\n",
            "\n",
            "üìö Knowledge Retrieved from unified_data.pdf:\n",
            "   ‚Ä¢ 5 relevant sections found\n",
            "   ‚Ä¢ Pages referenced: 3089, 1318, 2909, 1170, 694\n",
            "   ‚Ä¢ Top match preview: 91......\n",
            "\n",
            "üéØ Response Quality: high\n",
            "‚è∞ Generated at: 2025-09-11 23:47:02\n",
            "==========================================================================================\n",
            "üåä [Session 2] Your marine research question: What is the depth of Marina trench ?\n",
            "\n",
            "üîç [Analyzing] Consulting unified marine research database...\n",
            "üîç Analyzing question: What is the depth of Marina trench ?\n",
            "\n",
            "ü§ñ UNIFIED MARINE AI EXPERT RESPONSE:\n",
            "------------------------------------------------------------\n",
            "The depth of the Mariana Trench is approximately 11,034 meters (36,201 feet) below sea level. This is the lowest point on Earth, according to the National Oceanic and Atmospheric Administration (NOAA).\n",
            "\n",
            "To put this in perspective, consider that the pressure at the bottom of the trench is over 1,000 times greater than the standard atmospheric pressure at sea level. This extreme pressure requires specialized equipment and vessels designed to withstand such conditions.\n",
            "\n",
            "The Mariana Trench is located in the Pacific Ocean, to the east of the Mariana Islands. It's a remarkable natural feature that has garnered significant scientific attention due to its unique environment and potential for discovering new species.\n",
            "\n",
            "Marine scientists use various techniques to study the ocean's depths, including remote-operated vehicles (ROVs), autonomous underwater vehicles (AUVs), and deep-sea submersibles. These tools allow researchers to explore and map the seafloor in unprecedented detail, shedding light on the mysteries of our planet's oceans.\n",
            "\n",
            "In terms of marine AI applications, there are several areas where technology is being used to improve our understanding of ocean depths and ecosystems. For example, machine learning algorithms can be employed to analyze large datasets of oceanographic and biological data, helping scientists identify patterns and trends that might not be apparent through manual analysis alone.\n",
            "\n",
            "Moreover, advancements in underwater sensors and communication technologies enable real-time monitoring of ocean conditions, including temperature, salinity, and depth. This information is crucial for predicting weather patterns, tracking climate change, and managing marine resources sustainably.\n",
            "\n",
            "In conclusion, the Mariana Trench is an awe-inspiring natural wonder that continues to captivate scientists and the public alike. By leveraging cutting-edge technologies and methodologies, we can gain a deeper understanding of our oceans' depths and work towards preserving these incredible ecosystems for future generations.\n",
            "\n",
            "üìö Knowledge Retrieved from unified_data.pdf:\n",
            "   ‚Ä¢ 5 relevant sections found\n",
            "   ‚Ä¢ Pages referenced: 2099, 2827, 2759, 293\n",
            "   ‚Ä¢ Top match preview: The  standard_names  for  eta and  depth and  the  computed_standard_name must  be  one  of  the  co...\n",
            "\n",
            "üéØ Response Quality: high\n",
            "‚è∞ Generated at: 2025-09-11 23:47:45\n",
            "==========================================================================================\n",
            "üåä [Session 3] Your marine research question: quit\n",
            "\n",
            "üêô Thank you for exploring unified marine AI research!\n",
            "üìä Total questions asked: 2\n",
            "üåä Keep protecting our oceans! üåä\n"
          ]
        }
      ],
      "source": [
        "# Interactive chat interface for Unified Marine Biodiversity AI Expert\n",
        "def start_unified_marine_chat():\n",
        "    \"\"\"Interactive chat with the unified marine biodiversity expert\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"üåä\" * 35)\n",
        "    print(\"UNIFIED MARINE BIODIVERSITY AI EXPERT\")\n",
        "    print(\"üåä\" * 35)\n",
        "    print(\"\\nü§ñ Powered by Llama 3.2 3B + Unified Marine Research Dataset\")\n",
        "    print(\"üìö Single comprehensive knowledge source: unified_data.pdf\")\n",
        "\n",
        "    print(\"\\nüéØ Comprehensive Marine Expertise:\")\n",
        "    print(\"   üêü Advanced Aquaculture & Fish Farming Technologies\")\n",
        "    print(\"   üåä Marine Conservation & Ecosystem Protection\")\n",
        "    print(\"   üìä Ocean Data Science & GIS Integration\")\n",
        "    print(\"   üé£ Sustainable Fisheries & Resource Management\")\n",
        "    print(\"   üî¨ Species Identification & Biodiversity Monitoring\")\n",
        "    print(\"   ü§ñ AI Applications in Marine Science\")\n",
        "    print(\"   üå°Ô∏è Climate Change & Ocean Health\")\n",
        "    print(\"   üí° Innovation & Future Technologies\")\n",
        "\n",
        "    print(\"\\nüí° Example questions for unified dataset:\")\n",
        "    print(\"   ‚Ä¢ How does AI revolutionize marine aquaculture operations?\")\n",
        "    print(\"   ‚Ä¢ What integrated approaches exist for ocean conservation?\")\n",
        "    print(\"   ‚Ä¢ How do predictive models enhance fisheries management?\")\n",
        "    print(\"   ‚Ä¢ What role does big data play in marine research?\")\n",
        "    print(\"   ‚Ä¢ How are IoT networks transforming ocean monitoring?\")\n",
        "\n",
        "    print(\"\\nüìù Commands: Type 'quit' to exit, 'help' for more examples\")\n",
        "    print(\"üåä\" + \"-\" * 68 + \"üåä\\n\")\n",
        "\n",
        "    chat_session = 1\n",
        "    conversation_history = []\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Get user input\n",
        "            user_question = input(f\"üåä [Session {chat_session}] Your marine research question: \").strip()\n",
        "\n",
        "            # Handle special commands\n",
        "            if user_question.lower() in ['quit', 'exit', 'bye', 'stop']:\n",
        "                print(f\"\\nüêô Thank you for exploring unified marine AI research!\")\n",
        "                print(f\"üìä Total questions asked: {chat_session - 1}\")\n",
        "                print(f\"üåä Keep protecting our oceans! üåä\")\n",
        "                break\n",
        "\n",
        "            elif user_question.lower() == 'help':\n",
        "                print(\"\\nüÜò ADDITIONAL EXAMPLE QUESTIONS:\")\n",
        "                help_questions = [\n",
        "                    \"What are the latest innovations in precision aquaculture?\",\n",
        "                    \"How does computer vision detect marine pollution?\",\n",
        "                    \"What AI techniques optimize fish health monitoring?\",\n",
        "                    \"How do satellite systems monitor ocean biodiversity?\",\n",
        "                    \"What sustainable technologies exist for marine farming?\",\n",
        "                    \"How does machine learning predict fish stock dynamics?\",\n",
        "                    \"What role does automation play in marine research?\",\n",
        "                    \"How are drones used in marine ecosystem monitoring?\"\n",
        "                ]\n",
        "                for i, q in enumerate(help_questions, 1):\n",
        "                    print(f\"   {i}. {q}\")\n",
        "                print(\"\\nüåä Try any of these or ask your own question!\\n\")\n",
        "                continue\n",
        "\n",
        "            # Skip empty questions\n",
        "            if not user_question:\n",
        "                print(\"‚ùì Please ask a question about marine science!\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nüîç [Analyzing] Consulting unified marine research database...\")\n",
        "\n",
        "            # Get response from unified chatbot\n",
        "            response = marine_bot.ask_marine_question(user_question)\n",
        "\n",
        "            # Display formatted response\n",
        "            print(\"\\n\" + \"ü§ñ UNIFIED MARINE AI EXPERT RESPONSE:\")\n",
        "            print(\"-\" * 60)\n",
        "            print(response[\"answer\"])\n",
        "\n",
        "            # Show knowledge source information\n",
        "            if response[\"sources\"]:\n",
        "                print(f\"\\nüìö Knowledge Retrieved from {response['source_document']}:\")\n",
        "                print(f\"   ‚Ä¢ {len(response['sources'])} relevant sections found\")\n",
        "                print(f\"   ‚Ä¢ Pages referenced: {', '.join(set(str(s['page']) for s in response['sources']))}\")\n",
        "\n",
        "                # Show top source preview\n",
        "                top_source = response[\"sources\"][0]\n",
        "                print(f\"   ‚Ä¢ Top match preview: {top_source['content_preview'][:100]}...\")\n",
        "\n",
        "            print(f\"\\nüéØ Response Quality: {response['confidence']}\")\n",
        "            print(f\"‚è∞ Generated at: {response['timestamp']}\")\n",
        "\n",
        "            # Store in conversation history\n",
        "            conversation_history.append({\n",
        "                \"question\": user_question,\n",
        "                \"timestamp\": response['timestamp'],\n",
        "                \"confidence\": response['confidence']\n",
        "            })\n",
        "\n",
        "            print(\"=\" * 90)\n",
        "            chat_session += 1\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(f\"\\n\\nüêô Chat interrupted. Session summary:\")\n",
        "            print(f\"   ‚Ä¢ Questions answered: {chat_session - 1}\")\n",
        "            print(f\"   ‚Ä¢ Powered by unified marine research dataset\")\n",
        "            print(f\"üåä Thanks for exploring marine AI!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ö†Ô∏è Error: {str(e)}\")\n",
        "            print(\"Please try rephrasing your question.\")\n",
        "\n",
        "# Start the unified interactive chat\n",
        "start_unified_marine_chat()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPr1kJGeZSWFvR5qGLHnLJ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0552dfa5a7e04598ad75a5f791c94386": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0587c16aa5594a2790547dcae1602481": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "066717c0e0744e91b5fc218381be235f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cb6d5ce24ee4861a1c9b393baa03507": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ab792cd6a7f4598a394eaf810ecf36e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_99b854ec2b9d4a65a0dd17884f02cf49",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "1008c9750bc74a7d847c20b2e2caffb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106d394130e34ffdbe5249eb32c0ef77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34a5d39fe1a04544aeb29b5a77bf2716",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3115fb7099e146b9a8d5155cd8d5a6f4",
            "value": "‚Äá116/116‚Äá[00:00&lt;00:00,‚Äá8.00kB/s]"
          }
        },
        "10f9de9d5f3c4426a92218ebc09d0922": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "140d67a8ca6b4cd3ba154182857d93a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_411b54a9d1374a7aaee8a2915b2034ce",
              "IPY_MODEL_3258664961e344a8b52243e2987b4620",
              "IPY_MODEL_ae7fdc0090ce43f2b8e59e989f81851a"
            ],
            "layout": "IPY_MODEL_8482b516df494618b06be9513f5b7816"
          }
        },
        "18fb5a6eed394731880327de8bd9d54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_883fbe31840f4e53b66946c4aff12de6",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4753c515009a42fab226de83517e0186",
            "value": 53
          }
        },
        "1b9b77ee12dc419381e531ce25ffe385": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9628de1ae5bd4e1e9a39f2a63999afac",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_75a7bee87e5b44b29cc23440ad9812a3",
            "value": "config.json:‚Äá100%"
          }
        },
        "1d98fc70ff7f4a67b1a4695e19dd8f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e3eb3c2c76842afb0931826d9ea7576": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ea8e8a9aeba4480bece634a0f16b3cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ffe6bff2a55469daffcd143a8482455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2542d37312dc4e9d9e5e6c4351a5b618": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25686034010542959aec70df912884d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26ebb50e0b084c888bbf8b0fbbdec8b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26fd448b36f34b3f8cbdf3cb2196c35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dc010fcfeb94154adf4fcff78b8c487": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3115fb7099e146b9a8d5155cd8d5a6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3258664961e344a8b52243e2987b4620": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e104576692a04f1abe0895f5b3b799be",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db8b1c94c02440dfb0343cff6e848e36",
            "value": 190
          }
        },
        "3446ad167ffa497b90de580ec69585e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_713cf146006b4ed4bc5c64cc19c3f653",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_50e8289a0cc34824b6c56d9232107265",
            "value": "vocab.txt:‚Äá"
          }
        },
        "344a16b1a7e34747b179bc95d7b5bb2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a5d39fe1a04544aeb29b5a77bf2716": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382f3189a52946ec8de9f2bbebb86f77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bfb28c7483b4e4690d4f2b2229ab184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4df7169451284cadb849bb75f37394df",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c999db4eebb349739744ca4b187e4727",
            "value": "sentence_bert_config.json:‚Äá100%"
          }
        },
        "3ca56633bc784ad1a3932c06c9a39fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f61716bdde84247ae19f2bfbe1d18a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5c190b85bb349c7811f96df43eadf82",
              "IPY_MODEL_b1b6ab133a064f25afc75f6810e2e16b",
              "IPY_MODEL_728d66626a8c4dcc90cdb72eb3a51a90"
            ],
            "layout": "IPY_MODEL_f388a98a28ae496597e62f7ad333706b"
          }
        },
        "411b54a9d1374a7aaee8a2915b2034ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d72b882449fa46918ccfbec6b2f0255e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1d98fc70ff7f4a67b1a4695e19dd8f2c",
            "value": "config.json:‚Äá100%"
          }
        },
        "425d11e7a5814d0c96a4e51a95323399": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4753c515009a42fab226de83517e0186": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4809d29e1b594676979f559bc47e7321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c5f4fd0703942cea405358b5ee86365",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7d055de0b93841aaa47301f06f88e024",
            "value": "config_sentence_transformers.json:‚Äá100%"
          }
        },
        "4aa64bbd563c436b8866b9fedd6b1341": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a10ec537a726460d87bc287ca9d34e6c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cfebc1fb779c4d5c90cedb9f336ea6b2",
            "value": "‚Äá10.5k/?‚Äá[00:00&lt;00:00,‚Äá972kB/s]"
          }
        },
        "4c32a8c3e63c46daaf3aee34188c274a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9da54dea09fa46a4bce2d238de4bcdc1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fe448548cbcc41bc9d6543c38e15796d",
            "value": "‚Äá612/612‚Äá[00:00&lt;00:00,‚Äá66.2kB/s]"
          }
        },
        "4df7169451284cadb849bb75f37394df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50e8289a0cc34824b6c56d9232107265": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52bc91c73c93408eb6d3ce4a5f2c3e70": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54a8e03aba374ecb8de7ec1f217d1ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55a8679f3bb14c27bb5f05f5fd10cd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba325d9e2f8949e8a1208f570d5347d2",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2542d37312dc4e9d9e5e6c4351a5b618",
            "value": 612
          }
        },
        "55eac62490a44156b690063add335234": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ab792cd6a7f4598a394eaf810ecf36e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e9ed78845a3439ab2004185de96c738": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b9b77ee12dc419381e531ce25ffe385",
              "IPY_MODEL_55a8679f3bb14c27bb5f05f5fd10cd5c",
              "IPY_MODEL_4c32a8c3e63c46daaf3aee34188c274a"
            ],
            "layout": "IPY_MODEL_e00833a7c63d4af7824a0012ab95d467"
          }
        },
        "5f40d467e0cc4d829dd5d4e185c9d230": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f42007e9ede48faba72eb86e1c8b759": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bfb28c7483b4e4690d4f2b2229ab184",
              "IPY_MODEL_18fb5a6eed394731880327de8bd9d54d",
              "IPY_MODEL_e347f31896824e9dafd7a2cea0e64e30"
            ],
            "layout": "IPY_MODEL_659ddd06371f4fe8ba0fdb4de83d558c"
          }
        },
        "606c3cdebb5e4b7ea8034e89d5a20806": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6096e8eb37ef4239a8552cb7598ee600": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "629c3f8227bf4f928324697ed94ab4b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "659ddd06371f4fe8ba0fdb4de83d558c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "688414eed44a42f68be66f6034158f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e91c359cc7914a2d9ad85b6ce71854a8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_066717c0e0744e91b5fc218381be235f",
            "value": "modules.json:‚Äá100%"
          }
        },
        "713cf146006b4ed4bc5c64cc19c3f653": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "728d66626a8c4dcc90cdb72eb3a51a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e048d59e32894c5e98b01b4f4d5d8350",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7ff522f4fddc4bf7b7b1f3a85d7157ea",
            "value": "‚Äá350/350‚Äá[00:00&lt;00:00,‚Äá23.2kB/s]"
          }
        },
        "75a7bee87e5b44b29cc23440ad9812a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7be907e2be9b4d34bd2b971d137376ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea2d76bfa6e947e499e888db15942001",
              "IPY_MODEL_8f08d73e45ae4e8c87077571b0a5585b",
              "IPY_MODEL_daf4e50455984651a74c91f7879a4938"
            ],
            "layout": "IPY_MODEL_382f3189a52946ec8de9f2bbebb86f77"
          }
        },
        "7d055de0b93841aaa47301f06f88e024": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ff522f4fddc4bf7b7b1f3a85d7157ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83a6bd96e8af44f494f3159c6b21723c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8482b516df494618b06be9513f5b7816": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883fbe31840f4e53b66946c4aff12de6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88436314c0914ad190c89e79d73a4c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6096e8eb37ef4239a8552cb7598ee600",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ffe6bff2a55469daffcd143a8482455",
            "value": 1
          }
        },
        "8876892c87ea4a62b23c5332bac0a02e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "889138c2a3bd4740b36a4f9b1c71492f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bf4f5b6d14a4d6f824883754e45b30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c5f4fd0703942cea405358b5ee86365": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c9cf1f9961f4feba64488cb452fd6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f08d73e45ae4e8c87077571b0a5585b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f40d467e0cc4d829dd5d4e185c9d230",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5d90d8c85c0452da4722dc9d170afc2",
            "value": 90868376
          }
        },
        "9418012517664dd99b97b41a3a62599f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9628de1ae5bd4e1e9a39f2a63999afac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99b854ec2b9d4a65a0dd17884f02cf49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cedd375484d41ed924d5ded708b0bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad74fd057b334d4bacb1284b68b26b2a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cac8db10d20949e2a60e2caf63183841",
            "value": "‚Äá349/349‚Äá[00:00&lt;00:00,‚Äá27.2kB/s]"
          }
        },
        "9da54dea09fa46a4bce2d238de4bcdc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a10ec537a726460d87bc287ca9d34e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d874ad26344981a9054120e9abb8b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3446ad167ffa497b90de580ec69585e2",
              "IPY_MODEL_d9cf0afe718c4ca7a9b47ac4101ebb9a",
              "IPY_MODEL_de296a25aa004cdd996787d438d4105d"
            ],
            "layout": "IPY_MODEL_1ea8e8a9aeba4480bece634a0f16b3cd"
          }
        },
        "a5d90d8c85c0452da4722dc9d170afc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad74fd057b334d4bacb1284b68b26b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae7fdc0090ce43f2b8e59e989f81851a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3e5057c5cf642b89e1ce2e5caa61b22",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fb0d0371be1446388918aca49951dfa8",
            "value": "‚Äá190/190‚Äá[00:00&lt;00:00,‚Äá18.6kB/s]"
          }
        },
        "aed2c0c863b14256bbec85f2bf47d063": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec4c9dc6bd2f47c5b3a02051c6eeb952",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dfb3ed7822d5402d8418dafc00d625ad",
            "value": "‚Äá112/112‚Äá[00:00&lt;00:00,‚Äá8.46kB/s]"
          }
        },
        "aef44a0386db48bfa106d6a46b704b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54a8e03aba374ecb8de7ec1f217d1ecd",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b62de217554f4d1fa1b63f6c65c88ace",
            "value": 349
          }
        },
        "af0402434ce84b50aa6f613e8e569662": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8876892c87ea4a62b23c5332bac0a02e",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbd3a88c62014cbd9ffc63c0516d176d",
            "value": 116
          }
        },
        "b0eb4a8190d541b4b78fa6b57a4bf21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfa9fb854f9f44b394254b6952dd8188",
              "IPY_MODEL_eb4e16c2ccbd4156a7fae28e2c242e83",
              "IPY_MODEL_cdab7c65f62e4323aa4a4c3cd8ed1cfc"
            ],
            "layout": "IPY_MODEL_629c3f8227bf4f928324697ed94ab4b0"
          }
        },
        "b1b6ab133a064f25afc75f6810e2e16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10f9de9d5f3c4426a92218ebc09d0922",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55eac62490a44156b690063add335234",
            "value": 350
          }
        },
        "b29f39851a104709b295d660d8a41eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3edf700ebc34a4db7564e13345d380c",
              "IPY_MODEL_88436314c0914ad190c89e79d73a4c35",
              "IPY_MODEL_4aa64bbd563c436b8866b9fedd6b1341"
            ],
            "layout": "IPY_MODEL_fa36184e1ef04ecfa1ecaf3aec9adbb8"
          }
        },
        "b3e5057c5cf642b89e1ce2e5caa61b22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42ae7b68d00467e91ee97d7085a768d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4f924740b2f48238f3e1167bc31c29f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b62de217554f4d1fa1b63f6c65c88ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba325d9e2f8949e8a1208f570d5347d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa9fb854f9f44b394254b6952dd8188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_889138c2a3bd4740b36a4f9b1c71492f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_606c3cdebb5e4b7ea8034e89d5a20806",
            "value": "tokenizer.json:‚Äá"
          }
        },
        "c152599403704a5fb30ee4a9200496af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c522a5cadf0b46e0b7f67aa760e56d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_688414eed44a42f68be66f6034158f8d",
              "IPY_MODEL_aef44a0386db48bfa106d6a46b704b08",
              "IPY_MODEL_9cedd375484d41ed924d5ded708b0bba"
            ],
            "layout": "IPY_MODEL_344a16b1a7e34747b179bc95d7b5bb2a"
          }
        },
        "c999db4eebb349739744ca4b187e4727": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cac8db10d20949e2a60e2caf63183841": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb074c2cad4e46f8901f8b822ab022a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4809d29e1b594676979f559bc47e7321",
              "IPY_MODEL_af0402434ce84b50aa6f613e8e569662",
              "IPY_MODEL_106d394130e34ffdbe5249eb32c0ef77"
            ],
            "layout": "IPY_MODEL_1008c9750bc74a7d847c20b2e2caffb9"
          }
        },
        "cdab7c65f62e4323aa4a4c3cd8ed1cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f19e36c03a744299815babaa1b82a650",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8c9cf1f9961f4feba64488cb452fd6d1",
            "value": "‚Äá466k/?‚Äá[00:00&lt;00:00,‚Äá11.9MB/s]"
          }
        },
        "cfebc1fb779c4d5c90cedb9f336ea6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5c190b85bb349c7811f96df43eadf82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9418012517664dd99b97b41a3a62599f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_db3e8c81304b4cf1b0af186cd3f452a6",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "d72b882449fa46918ccfbec6b2f0255e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9cf0afe718c4ca7a9b47ac4101ebb9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb4c1ba5915947d2835f870543987510",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b42ae7b68d00467e91ee97d7085a768d",
            "value": 1
          }
        },
        "daf4e50455984651a74c91f7879a4938": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e3eb3c2c76842afb0931826d9ea7576",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c152599403704a5fb30ee4a9200496af",
            "value": "‚Äá90.9M/90.9M‚Äá[00:01&lt;00:00,‚Äá68.3MB/s]"
          }
        },
        "db3e8c81304b4cf1b0af186cd3f452a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db8b1c94c02440dfb0343cff6e848e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbd3a88c62014cbd9ffc63c0516d176d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de296a25aa004cdd996787d438d4105d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f924740b2f48238f3e1167bc31c29f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_25686034010542959aec70df912884d2",
            "value": "‚Äá232k/?‚Äá[00:00&lt;00:00,‚Äá3.62MB/s]"
          }
        },
        "dfb3ed7822d5402d8418dafc00d625ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e00833a7c63d4af7824a0012ab95d467": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e048d59e32894c5e98b01b4f4d5d8350": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e104576692a04f1abe0895f5b3b799be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e347f31896824e9dafd7a2cea0e64e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52bc91c73c93408eb6d3ce4a5f2c3e70",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8bf4f5b6d14a4d6f824883754e45b30b",
            "value": "‚Äá53.0/53.0‚Äá[00:00&lt;00:00,‚Äá4.30kB/s]"
          }
        },
        "e3edf700ebc34a4db7564e13345d380c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_425d11e7a5814d0c96a4e51a95323399",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3ca56633bc784ad1a3932c06c9a39fc1",
            "value": "README.md:‚Äá"
          }
        },
        "e4d97fe631de40e79d04259b424baaba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cb6d5ce24ee4861a1c9b393baa03507",
              "IPY_MODEL_ff80f17e9c53428081d5a9fc927e8766",
              "IPY_MODEL_aed2c0c863b14256bbec85f2bf47d063"
            ],
            "layout": "IPY_MODEL_eb4ca1a24e4f41f6bb8c0886d17929c1"
          }
        },
        "e91c359cc7914a2d9ad85b6ce71854a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea2d76bfa6e947e499e888db15942001": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26ebb50e0b084c888bbf8b0fbbdec8b5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_26fd448b36f34b3f8cbdf3cb2196c35a",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "eb4c1ba5915947d2835f870543987510": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "eb4ca1a24e4f41f6bb8c0886d17929c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb4e16c2ccbd4156a7fae28e2c242e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83a6bd96e8af44f494f3159c6b21723c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0587c16aa5594a2790547dcae1602481",
            "value": 1
          }
        },
        "ec4c9dc6bd2f47c5b3a02051c6eeb952": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f19e36c03a744299815babaa1b82a650": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f388a98a28ae496597e62f7ad333706b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa36184e1ef04ecfa1ecaf3aec9adbb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb0d0371be1446388918aca49951dfa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe448548cbcc41bc9d6543c38e15796d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff80f17e9c53428081d5a9fc927e8766": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0552dfa5a7e04598ad75a5f791c94386",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2dc010fcfeb94154adf4fcff78b8c487",
            "value": 112
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}